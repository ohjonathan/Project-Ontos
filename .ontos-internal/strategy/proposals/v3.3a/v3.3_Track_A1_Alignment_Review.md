---
id: v3_3_track_a1_alignment_review
type: strategy
status: active
depends_on: [v3_3_track_a1_implementation_spec, v3_3_merged_audit_findings, v3_3_release_plan]
concepts: [v3.3, alignment-review, track-a1, code-review, phase-d]
---

# v3.3 Track A1 — Alignment Review

> **Reviewer:** Antigravity, powered by Gemini 2.5 Pro (Alignment Reviewer)
> **Date:** 2026-02-11
> **PR:** [#67](https://github.com/ohjonathan/Project-Ontos/pull/67)
> **Branch:** `feature/v3.3-track-a1-unified-loader` (4 commits ahead of `main`)
> **Reference Docs:** Implementation Spec, Merged Audit Findings, Release Plan

---

## 1. Settled Decision Compliance Matrix

| Decision | Implemented Correctly? | Evidence | Notes |
|----------|----------------------|----------|-------|
| **S4: Canonical parser = IO YAML** | ✅ Yes | `load_documents()` and `load_frontmatter()` in `io/files.py` both accept `frontmatter_parser` param; all command callers pass `parse_frontmatter_content`. `parse_frontmatter()` (core) marked NON-CANONICAL in docstring. `parse_frontmatter_yaml()` (io/yaml) demoted to thin wrapper around `parse_frontmatter_content`. | No remaining command code path creates a third parsing contract. |
| **S4: Parse failure = skip + warn** | ✅ Yes | `load_documents()` catches `(ValueError, UnicodeDecodeError)` and `OSError`, records `DocumentLoadIssue(code="parse_error")`, and continues to next file. `load_frontmatter()` returns `(None, None)` on failure. No abort. | Consistent across both loader APIs. |
| **B5: Duplicate ID detection infrastructure** | ✅ Yes | `load_documents()` detects duplicates centrally, records each collision in `DocumentLoadResult.duplicate_ids` (Dict[str, List[Path]]), and emits `DocumentLoadIssue(code="duplicate_id")` with all participating file paths. Determinism via `sorted(paths)` with first-wins semantics. `ValidationErrorType.DUPLICATE_ID` added to `core/types.py`. | Infrastructure is reusable; both `link-check` and `rename` can invoke `load_documents()` and inspect `duplicate_ids`. |

---

## 2. Layer Boundary Compliance

### CC-01 Fix (core→IO import removal)

✅ **Verified.** `core/snapshot.py` no longer contains any `from ontos.io` imports. The `create_snapshot()` function was moved to `io/snapshot.py`, which correctly lives in the IO layer. `core/snapshot.py` retains only pure domain types (`SnapshotFilters`, `DocumentSnapshot`, `matches_filter`).

### Pre-existing core→IO import

> [!NOTE]
> `core/config.py:232` contains `from ontos.io.git import get_file_mtime`. This import is **pre-existing** (not introduced by A1) and is **not in scope** for this track. Flagged for awareness only.

### New layer violations introduced by A1?

✅ **None found.** All new IO operations (`load_documents`, `load_frontmatter`, `create_snapshot`) are in `io/` layer. Core modules (`frontmatter.py`, `validation.py`, `graph.py`, `snapshot.py`, `types.py`, `staleness.py`) import only from `core/` or standard library.

### Parser unification boundary handling

`core/frontmatter.py` provides normalization functions (`normalize_reference_list`, `normalize_type`, `normalize_status`) that are called by `io/files.py:load_document_from_content()`. This is correct: the IO boundary calls into core for domain logic, not the reverse.

---

## 3. Backward Compatibility Assessment

### User-visible behavioral changes

| Change | Impact | Justified? |
|--------|--------|------------|
| `map` now exits 1 on duplicate IDs or parse errors (`has_fatal_errors`) | **Behavioral change.** Previously, `map` silently overwrote duplicates and printed a generic warning for parse failures. Now it prints specific error messages and exits 1. | ✅ Yes — required by #10 spec. Duplicates made graph nondeterministic. |
| `maintain check_links` now reports load issues (parse errors, duplicates) in task details/metrics | **Behavioral change.** Previously, parse errors were silently swallowed. Now they appear in task output with `LOAD` prefix labels. | ✅ Yes — required by #11 (C-9) and #10. |
| `query` now exits 1 on `has_fatal_errors` | **Behavioral change.** Previously, parse failures were silently skipped. | ✅ Yes — consistent with canonical loader contract. |
| Validation warnings now appear for broken `impacts`/`describes` references at configurable severity | **Behavioral change.** Previously, `impacts` warnings were always hardcoded; `describes` was handled by a scalar-only function. Now severity is config-driven. Default behavior is preserved (impacts=warning, describes=warning). | ✅ Yes — required by #44. Defaults match prior behavior. |
| Log documents without `concepts` field now emit a warning | **New validation.** Previously, `validate_concepts()` existed but was never called. | ✅ Yes — required by #42. |
| `core/snapshot.create_snapshot` no longer exists | **Internal API break.** Moved to `io/snapshot.create_snapshot`. | ✅ Yes — documented in spec §7. Tests updated (`test_snapshot.py`, `test_migration.py`). |
| `core/snapshot._matches_filter` renamed to `matches_filter` | **Internal API change.** Public visibility increased. | ✅ Yes — needed for `io/snapshot.py` to import it. |
| `load_document_from_content()` return type changed from `DocumentData` to `Tuple[DocumentData, List[DocumentLoadIssue]]` | **Internal API break.** All callers updated in-track. | ✅ Yes — necessary for issue reporting (#1, S4). |

### CLI surface changes

✅ **No CLI command names or flags were changed.** Track A1 is infrastructure-only.

### Test modifications

Two existing test files were updated to change imports:
- `tests/core/test_snapshot.py`: imports `create_snapshot` from `ontos.io.snapshot`
- `tests/core/test_migration.py`: same import change

These changes are consistent with the snapshot refactor (#33) and do not indicate behavioral regression.

---

## 4. Contract Consistency

### Canonical loading contract

✅ **Clear and consistent.**
- `load_frontmatter(path, parser, on_issue?) → (dict|None, str|None)` — single-file, returns frontmatter+body
- `load_documents(paths, parser, cache?) → DocumentLoadResult` — batch, returns rich result with issues/duplicates
- `DocumentLoadResult` has `.documents`, `.issues`, `.duplicate_ids`, `.has_errors`, `.has_fatal_errors`
- `DocumentLoadIssue` has typed `.code` field: `parse_error | duplicate_id | invalid_enum | invalid_reference_type | io_error`

### Duplicate detection API

✅ **Consistent with validation patterns.** Returns structured `DocumentLoadIssue` objects with codes, paths, and messages. Callers decide severity (map → exit 1, query → exit 1, maintain → task failed, snapshot → warn).

### Validation severity model

✅ **Implemented with correct hierarchy.** Constants defined in `core/graph.py` (`DEPENDS_ON_SEVERITY_DEFAULT`, `IMPACTS_SEVERITY_DEFAULT`, `DESCRIBES_SEVERITY_DEFAULT`) and consumed by `core/validation.py` via `REFERENCE_SEVERITY_DEFAULT` dict. Orchestrator merges caller overrides via `config.get("severity_map", {})`.

### Normalization functions

✅ **Single source of truth established.** `normalize_reference_list()` is canonical for `depends_on`/`impacts`. `normalize_depends_on()` is a thin wrapper. `normalize_describes()` in `staleness.py` follows the same pattern with `on_warning` callback. `normalize_type()`/`normalize_status()` in `frontmatter.py` return enums directly, catching both `ValueError` and `TypeError` (#25).

---

## 5. Track B Readiness Assessment

### Parse frontmatter for reading

✅ `load_frontmatter()` provides direct frontmatter access for single files.

### Parse frontmatter for modification

✅ `load_frontmatter()` returns raw body alongside frontmatter dict, enabling read-modify-write flows.

### Parse with error recovery

✅ `load_documents()` skips failures, records issues, and continues. `DocumentLoadResult.issues` gives Track B full visibility into parse failures.

### Duplicate detection callable from both link-check and rename

✅ `load_documents()` returns `duplicate_ids` and issues; both commands can call it and apply their own severity policies.

### Unified graph builder for link-check queries

✅ `core.graph.build_graph()` is the single implementation; query's duplicate was removed (#36). Supports broken ref detection, orphan detection, and cycle detection. Parameterized severity map enables Track B to override defaults.

### Anything that would BLOCK Track B?

✅ **No blockers identified.** A1 delivers all four prerequisite items (#1, #10, #42, #44) the release plan requires.

---

## 6. Scope Creep Check

### In-scope items (12/12 implemented)

| Item | Status |
|------|--------|
| #1 (CC-03) Canonical parser | ✅ |
| #8 (C-5) describes list-safe | ✅ |
| #9 (C-7) depends_on/impacts normalization | ✅ |
| #10 (C-8) Duplicate ID detection | ✅ |
| #25 (C-6) Enum TypeError+ValueError | ✅ |
| #33 (CC-01) Core→IO boundary | ✅ |
| #36 (CC-05) Remove duplicate build_graph | ✅ |
| #37 (CC-06) Remove defensive enum checks | ✅ |
| #40 (CC-09) Canonical loading pattern | ✅ |
| #41 (CC-11) Single normalization source | ✅ |
| #42 (CC-16) Concepts validation | ✅ |
| #44 (CC-19) Severity model | ✅ |

### Extra changes beyond the 12 items

| Change | Classification | Assessment |
|--------|---------------|------------|
| `describes` field added to `DocumentData` dataclass | **Necessary extension.** Required for `describes` normalization at load time (#8, #41). | ✅ Justified |
| `CurationLevel` moved from `core/curation.py` to `core/types.py` | **Necessary refactor.** Avoids circular import when `types.py` re-exports `CurationLevel`. | ✅ Justified |
| `DocumentCache` import added to `io/files.py`; `load_documents` accepts optional cache | **Scope extension** but minimal. `map.py` already used caching; moving it into the canonical loader centralizes it. | ✅ Justified |
| BOM stripping + `.lstrip()` added to `load_document()` and `load_documents()` | **Robustness improvement** discovered during implementation. Matches what `read_file_lenient()` provided previously. | ✅ Justified |
| `scaffold.py` reworked to use canonical loader more extensively | **Broader than spec** — spec lists `scaffold.py` as parser migration target, but the scaffold command refactoring goes further (scanning, duplicate checking, archive exclusion). | ⚠️ See Concern C1 below |
| `_matches_filter` → `matches_filter` visibility change | **Necessary** for `io/snapshot.py` to import. | ✅ Justified |

---

## Alignment Issues

### Violations (Block Merge)

**None.**

### Concerns (Should Discuss)

> [!IMPORTANT]
> **C1: `REFERENCE_SEVERITY_RATIONALE` dict missing from code.**
>
> The Implementation Spec §4.3 specifies a `REFERENCE_SEVERITY_RATIONALE` dictionary alongside `REFERENCE_SEVERITY_DEFAULT`, providing human-readable justifications for each severity choice. The implementation defines `REFERENCE_SEVERITY_DEFAULT` (in `validation.py`) and the individual severity constants with inline comments (in `graph.py`), but does **not** define the `REFERENCE_SEVERITY_RATIONALE` dict as a code-level constant.
>
> **Impact:** Low. The rationale IS documented in comments (`# SEVERITY RATIONALE (v3.3 Track A1)` blocks in both `graph.py` and `validation.py`). However, the spec intended this to be a programmatically accessible dict, which could be useful for `--explain` or audit output in Track B.
>
> **Recommendation:** Non-blocking. Add `REFERENCE_SEVERITY_RATIONALE` as a code constant in a follow-up or during Track B when it's needed for user-facing explanations.

> [!NOTE]
> **C2: `map` severity_map overrides broken_link to "warning".**
>
> `map.py:generate_context_map()` passes `"severity_map": {"broken_link": "warning"}` to the `ValidationOrchestrator`. This means broken `depends_on` references are downgraded from errors to warnings during map generation. This is intentional (the context map generation has always been lenient to produce a map even with broken links), but it deviates from the spec's statement that `map` should treat duplicates as "hard errors (exit 1)".
>
> **Clarification:** The `has_fatal_errors` check in `map_command()` does exit 1 for duplicates (since `duplicate_id` is in the fatal codes set). The warning demotion is for `depends_on` validation only, not for duplicate ID detection. This is consistent with prior behavior where map would still generate even with broken links.
>
> **Impact:** None. Duplicate IDs correctly exit 1 via `has_fatal_errors`. Broken links being warnings during map generation preserves backward compatibility.

> [!NOTE]
> **C3: `scaffold.py` changes extend beyond parser migration.**
>
> The scaffold command received additional logic for archive exclusion patterns, duplicate ID noise suppression, and a pre-scan via `load_documents`. While individually reasonable, these changes go beyond the spec's scope of "parser caller migration." The additional archive exclusion patterns (`**/archive/**`, `**/tmp/**`, etc.) represent UX-level decisions that weren't in the A1 spec.
>
> **Impact:** Low. The changes are defensive and prevent noisy warnings during scaffold operations. No user-visible regression risk.
>
> **Recommendation:** Should be noted in the PR description as "discovered during implementation" changes.

### Observations (FYI)

> [!TIP]
> **O1: `has_fatal_errors` treats ALL duplicate IDs as fatal.**
>
> The `DocumentLoadResult.has_fatal_errors` property treats `duplicate_id` as uniformly fatal. The spec's policy table (#10) intended `query` and `snapshot` to treat duplicates as warnings, not fatal errors. Currently, `query` checks `has_fatal_errors` and exits 1 on duplicates, which is stricter than the spec intended.
>
> This is not an alignment violation (the spec says "Severity decided by caller," and callers can inspect issues directly instead of using `has_fatal_errors`). But it may cause unexpected `query` failures in projects with legitimate ID collisions during the migration period.
>
> **Future consideration:** Track B may want per-caller severity rather than relying on `has_fatal_errors`.

> [!NOTE]
> **O2: Known vocabulary for concept validation is self-referential.**
>
> `map.py` collects all concepts from loaded documents and passes them as `known_concepts` to the validator. This means every concept that exists in any document is automatically "known." The vocabulary check will therefore never fire unless a concept is typoed within a single file differently from all others.
>
> This is architecturally correct (the spec says "if `config['known_concepts']` provided, unknown → warning; if not provided, vocabulary check is skipped"). The map command provides the vocabulary, but the vocabulary IS the union of all documents. A stricter audit-mode vocabulary from a curated list would need separate infrastructure.

> [!NOTE]
> **O3: `DocumentLoadResult` property naming.**
>
> `has_errors` returns `True` if there are any issues at all (including informational ones like `invalid_enum` fallbacks). `has_fatal_errors` returns `True` for `duplicate_id`, `parse_error`, and `io_error`. The naming is slightly overloaded — `has_errors` is effectively `has_any_issues`. Not a problem now but worth noting for API documentation.

---

## Verdict

### **Approve with Observations**

The implementation correctly honors both binding decisions (S4 and B5), restores the core/IO boundary (CC-01), and delivers all 12 A1 items within scope. Layer boundaries are clean, backward compatibility is maintained for all user-visible behaviors, and the canonical loading contract provides a solid foundation for Track B.

The three concerns (C1–C3) are non-blocking:
- C1 is a missing convenience constant that can be added in Track B
- C2 is correctly understood once the `has_fatal_errors` check is traced
- C3 is minor scope extension in `scaffold.py` that should be documented

The three observations (O1–O3) are informational items for the team to consider as Track B proceeds.

**Track B can begin on this foundation.**
