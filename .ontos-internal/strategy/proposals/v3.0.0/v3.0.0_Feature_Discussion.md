# Project Ontos v3.0.0: Feature Discussion Document

**Purpose:** Gather feedback from multiple LLMs before finalizing the v3.0.0 implementation plan  
**Date:** 2026-01-15  
**Status:** Open for Discussion

---

## Context for Reviewers

This document describes the proposed features for Ontos v3.0.0. We're sharing it with multiple AI models (Claude, Gemini, Codex, etc.) to get diverse perspectives before committing to implementation.

**What is Ontos?**
Ontos is a local-first documentation management system for AI-assisted development. It creates a structured knowledge graph using YAML-tagged markdown files, enabling developers to share project context across different AI tools without repeatedly re-explaining architecture and decisions.

**Current State:**
- v3.0.1 is code-complete and merged
- Not yet published to PyPI
- Works reliably on Cursor (has `.cursorrules`)
- Unreliable on other LLM CLIs (Claude Code, Codex, Gemini CLI)

---

## The Core Problem

Ontos v3.0.1 is technically complete but practically broken. Here's the current user journey:

1. Someone discovers Ontos
2. They can't `pip install ontos` (not on PyPI)
3. They clone the repo, figure out installation manually
4. They run `ontos init`, everything works
5. They open their preferred LLM CLI and say "Activate Ontos"
6. **The LLM doesn't know what Ontos is.** Activation fails.

Step 6 is where we lose users. All the sophisticated features—dependency tracking, staleness detection, curation levels—are invisible because the LLM can't find them.

**The v3.0.0 goal:** Fix the activation problem so Ontos works reliably across all major LLM platforms.

---

## Proposed Features

### Feature 1: `ontos export` Command

**The Problem:**
Each LLM CLI has its own instruction file convention:

| LLM CLI | Expected File | Ontos Support Today |
|---------|--------------|---------------------|
| Claude Code | `CLAUDE.md` | ❌ None |
| Codex (OpenAI) | `AGENTS.md` | ❌ None |
| Gemini CLI | `GEMINI.md` | ❌ None |
| Cursor | `.cursorrules` | ✅ Exists |

When a user says "Activate Ontos" to Claude Code, Claude doesn't find a `CLAUDE.md` file. Sometimes it infers what to do. Often it asks "What is Ontos?" or guesses incorrectly.

**Why It Matters:**
This is the single biggest adoption blocker. Ontos claims to be "tool-agnostic"—your documentation should travel with your project regardless of which AI tool you use. But that's not true today. We're accidentally Cursor-exclusive.

**The Proposed Solution:**
Implement `ontos export` to generate platform-specific instruction files:

```bash
ontos export --format=claude     # → CLAUDE.md
ontos export --format=codex      # → AGENTS.md
ontos export --format=gemini     # → GEMINI.md
ontos export --format=cursor     # → .cursorrules
ontos export --all               # → All of the above
```

Each exported file would contain:
- Project declaration ("This project uses Ontos")
- Activation instructions (where to find context map)
- Session workflow (what to do at start/end of session)
- Key commands reference
- Project-specific stats (doc counts, staleness)

**Open Questions for Discussion:**

1. Should `ontos init` automatically generate all instruction files? Or require explicit `ontos export`?
   - Auto-generate: Zero friction for new users
   - Explicit: User chooses which platforms they care about
   
2. `AGENTS.md` is becoming a Linux Foundation standard (supported by Codex, Jules, Aider, and others). Should Ontos default to AGENTS.md as the "universal" format?
   - If yes: `ontos export` without flags generates AGENTS.md
   - If no: Require explicit `--format` flag always
   
3. How should we handle instruction file updates?
   - Option A: Manual only (`ontos export` when user wants)
   - Option B: Auto-regenerate on `ontos map`
   - Option C: Detect staleness and warn user

4. For LLMs reading this: **What would make the instruction file most useful to you?** What information do you need to effectively work with an Ontos-managed project?

---

### Feature 2: PyPI Publishing

**The Problem:**
You cannot `pip install ontos`. The package isn't on PyPI.

**Why It Matters:**
This is table stakes for a Python CLI tool. Without PyPI distribution:
- Users must clone the repository manually
- No version pinning in `requirements.txt`
- No automatic dependency resolution
- Signals "not production ready" to potential users

**The Proposed Solution:**
Set up GitHub Actions workflow for automated PyPI publishing using trusted publisher authentication (no API tokens to manage).

**Open Questions for Discussion:**

1. Is "ontos" available as a PyPI package name? (Unknown until we attempt to publish)
   - If taken, alternatives: `ontos-cli`, `project-ontos`, `ontos-docs`

2. Should we publish to TestPyPI first to verify everything works?

3. What version numbering convention going forward? (We're at 3.0.2)

---

### Feature 3: Archive Exclusion Fix

**The Problem:**
Running `ontos doctor` shows 39 validation errors from archived documents:

```
ERROR: Broken dependency in 'archive/planning/spec_unified_cli.md'
  - References 'v2_implementation_plan' which does not exist
```

These are documents in `archive/` directories that reference other documents that no longer exist.

**Why It Matters:**
These are false positives. Archived docs *should* have broken dependencies—that's often why they're archived. But the noise:
- Makes users think something is wrong
- Confuses LLMs during activation (they see errors and try to fix them)
- Buries real errors in noise
- Undermines trust in `ontos doctor`

**The Proposed Solution:**
Audit all code paths that scan documents and ensure `archive/` is consistently excluded.

**Open Questions for Discussion:**

1. Should archived documents ever be queryable?
   - Option A: Never (archive is a graveyard, completely ignored)
   - Option B: Optional (`ontos query --include-archived` flag)
   - Option C: Separate archive index for historical research

2. For LLMs: When you see validation errors during project activation, how do you handle them? Do you try to fix them? Ignore them? Ask the user?

---

### Feature 4: CLI Documentation

**The Problem:**
Ontos has 13 CLI commands. Users don't know what they do or when to use them.

The commands: `init`, `map`, `log`, `doctor`, `export`, `hook`, `verify`, `query`, `migrate`, `consolidate`, `promote`, `scaffold`, `stub`

`ontos --help` shows a list with minimal descriptions. No examples. No guidance on workflows.

**Why It Matters:**
Discoverability. If users don't know `ontos query --deps <id>` exists, they won't use it. If they don't understand `ontos log`, they won't do end-session logging, and session history becomes useless.

**The Proposed Solution:**
- Improve `--help` output for each command with examples
- Create a CLI reference document
- Include command quick-reference in exported instruction files

**Open Questions for Discussion:**

1. Where should the CLI reference live?
   - In the README (single source of truth)
   - Separate `docs/CLI_Reference.md`
   - Auto-generated from code docstrings

2. Should there be an `ontos help <command>` alias for `ontos <command> --help`?

3. For LLMs: What command information is most useful during a coding session? Full documentation or quick cheat-sheet?

---

### Feature 5: Golden Test Expansion

**The Problem:**
Only 2 golden tests exist. Output format changes could break user workflows without us noticing.

**Why It Matters:**
Ontos output is consumed by LLMs and user scripts. If `ontos map` format changes, prompts that parse it break. If `ontos export` templates change, instruction files may become malformed.

**The Proposed Solution:**
Add golden tests (expected output snapshots) for key commands:
- `ontos map` output
- `ontos doctor` output
- `ontos export` for each format

**Open Questions for Discussion:**

1. Is this P2 (nice to have) or should it be higher priority?

2. Which outputs are most critical to stabilize?

3. How do we handle dynamic content in golden tests (timestamps, document counts)?

---

### Feature 6: `ontos init` Idempotency

**The Problem:**
What happens if you run `ontos init` twice? The behavior is unclear. It might overwrite config, might error, might silently succeed.

**Why It Matters:**
Users shouldn't have to remember whether they've already initialized. Running `ontos init` should always be safe.

**The Proposed Solution:**
- Detect existing initialization and warn
- Require `--force` flag to reinitialize
- Optionally add `--upgrade` for schema migrations

**Open Questions for Discussion:**

1. Is this a real problem or theoretical? 
   - The project owner hasn't personally encountered this issue
   - But it's a common footgun in CLI tools

2. Should this be in v3.0.0 or deferred?

3. For LLMs: Have you seen users accidentally run init commands twice? What was the outcome?

---

## Priority Discussion

Current proposed priorities:

| Priority | Features | Rationale |
|----------|----------|-----------|
| **P0** (Must have) | `ontos export`, PyPI publishing | Without these, Ontos doesn't work on most platforms and can't be installed |
| **P1** (Should have) | Archive fix, CLI docs | Noise reduction and discoverability |
| **P2** (Nice to have) | Golden tests, init idempotency | Insurance and edge case handling |

**Open Questions for Discussion:**

1. Does this priority ranking feel right?

2. Should anything move up or down?

3. Is this the right scope for a point release (v3.0.0)? Too much? Too little?

4. Are we missing anything critical?

---

## Questions Specifically for LLM Reviewers

We'd especially appreciate your perspective on:

1. **Activation Experience:** When you encounter a project with Ontos, what signals help you understand how to work with it? What's confusing?

2. **Instruction File Content:** What information in a CLAUDE.md/AGENTS.md/GEMINI.md would be most useful for you to effectively assist with an Ontos-managed project?

3. **Error Handling:** When `ontos doctor` reports validation errors, how do you typically respond? Do you try to fix them? Ask the user? Ignore them?

4. **Command Discovery:** How do you learn what CLI commands are available in a project? Do you run `--help`? Look for documentation? Try common command names?

5. **Session Workflow:** Ontos expects an "end session" workflow where the LLM runs `ontos log` before finishing. Is this realistic? Would you remember to do this? What would help you remember?

6. **Format Preferences:** Do you have a preference between CLAUDE.md, AGENTS.md, GEMINI.md formats? Is there meaningful difference in how you process them?

---

## How to Provide Feedback

Please respond with:
1. Your overall assessment of the v3.0.0 scope
2. Answers to any open questions that are relevant to your experience
3. Concerns or risks you see
4. Suggestions we haven't considered

We'll synthesize feedback from multiple LLMs and update the implementation plan accordingly.

---

**Document End**

*This document will be shared with Claude, Gemini, Codex, and other AI models for feedback.*
