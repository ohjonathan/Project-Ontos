---
id: v3_1_0_sidecar_pattern
type: strategy
status: draft
depends_on: [v3_1_0_implementation_plan]
concepts: [sidecar, agents, performance, tokens, architecture]
---

# v3.1.0 Sidecar Pattern Strategy

**Status:** DRAFT
**Date:** 2026-01-18
**Theme:** "Agents Orchestrating Agents"
**Goal:** Enable a high-performance "Scanner" workflow where cheap, fast models identify relevant context for capable, expensive models.

---

## 1. The Problem

**Current State:**
Agents (like Gemini Pro or Claude Opus) often need to read full files to understand what they are about. In a large repository (300+ docs), reading the file tree or opening 20 files just to check their relevance consumes massive context (tokens) and time (latency).

**Cost:**
- **Tokens:** Reading headers of 300 docs = ~15k tokens.
- **Latency:** Opening/reading 300 files = ~5-10 seconds.
- **Context Pollution:** The model's context window fills with irrelevant noise.

---

## 2. The "Sidecar" Solution

The **Sidecar Pattern** splits the workload:

1.  **The Scanner (Sidecar):** A fast, cheap model (e.g., Gemini Flash) or a deterministic script (`ontos map --compact`) scans the *metadata* of the entire repository.
2.  **The Orchestrator:** The smart model (you) receives a highly compressed map of the territory.
3.  **Selective Loading:** The Orchestrator requests *only* the specific files identified as relevant by the Scanner.

---

## 3. Ontos Implementation: "Rich Compact Map"

To enable this, `ontos` must provide a "high-density, low-token" view of the world.

### 3.1 The `summary` Field
We standardize a `summary` field in the frontmatter.
- **Max length:** 100 characters.
- **Content:** Semantic description of the file's purpose.
- **Source:** Human-written or AI-generated.

### 3.2 The `--compact=rich` Output
The `ontos map` command gains a mode that outputs a format optimized for AI scanning:

```text
# FORMAT: ID | Type | Status | Summary
auth_core | atom | active | Core authentication logic and session management.
user_model | atom | active | User database schema and PII handling.
login_flow | atom | active | UX flow for user login and 2FA.
```

**Token Math:**
- Old Map (Table): ~2500 tokens (whitespace heavy)
- New Rich Map: ~1000 tokens (dense info)

### 3.3 The `--filter` Flag
The "Scanner" needs to find needles in the haystack without reading the hay.

```bash
# Scanner queries:
ontos map --filter "summary~authentication" --compact
ontos map --filter "type:atom status:active" --compact
```

---

## 4. Architecture Changes

### 4.1 IO-Efficient Parser (`ontos.core.frontmatter`)
- **Current:** Reads entire file to parse frontmatter.
- **New:** Reads *only* the first 50 lines (or until `---`).
- **Benefit:** 90% reduction in I/O for `ontos map`.

### 4.2 Document Cache (`ontos.core.cache`)
- **Memory Cache:** Stores parsed frontmatter in RAM during a session.
- **Persistent Cache:** (Future) Stores parsed metadata in `.ontos/cache.json` to speed up cold starts.

### 4.3 Query Engine (`ontos.core.query`)
- Expose the scanning logic as a library for other tools to use.

---

## 5. Workflow Example

**User:** "Fix the bug in the login retry logic."

**Agent (Orchestrator):**
1.  **Plan:** I need to find the login logic.
2.  **Action:** `ontos map --compact=rich --filter "summary~login"`
3.  **Result:**
    ```
    login_flow:atom:active:"UX flow for user login and 2FA."
    auth_retry_policy:atom:active:"Exponential backoff for failed logins."
    ```
4.  **Action:** `read_file auth_retry_policy.md`
5.  **Refinement:** "Ah, I see the bug in the backoff calculation."

**Total Tokens:** ~500 (vs ~15,000 to read everything).

---

## 6. Implementation Checklist

- [ ] **Standardize `summary`:** Update templates.
- [ ] **Optimize `parse_frontmatter`:** Stop reading after header.
- [ ] **Enhance `ontos map`:** Add `--compact` (bool/string) and `--filter`.
- [ ] **Update `ontos query`:** Use the new shared scanning engine.

---

*Chief Architect*
