---
id: v2_9_implementation_plan
type: strategy
status: complete
depends_on: [v2_8_implementation_plan]
concepts: [architecture, installation, schema, adoption]
---

# v2.9 Implementation Plan

**Author:** Claude Code (Opus 4.5) as Chief Architect
**Date:** 2025-12-23
**Version:** 1.5.0
**Goal:** Bridge V2 → V3 transition with improved onboarding, schema versioning, and flexible curation
**Status:** APPROVED — v2.9.4 (Documentation & Release) next

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Feature 1: install.py Bootstrap](#2-feature-1-installpy-bootstrap)
3. [Feature 2: Schema Versioning](#3-feature-2-schema-versioning)
4. [Feature 3: Curation Levels](#4-feature-3-curation-levels)
5. [Feature 4: Deprecation Warnings](#5-feature-4-deprecation-warnings)
6. [Implementation Phases](#6-implementation-phases)
7. [Open Questions — Resolved](#7-open-questions--resolved)
8. [Success Criteria](#8-success-criteria)
9. [Risk Analysis](#9-risk-analysis)
10. [Testing Strategy](#10-testing-strategy)
11. [Migration Guide](#11-migration-guide)
12. [Implementation Progress](#12-implementation-progress)
13. [LLM Review Board Feedback](#13-llm-review-board-feedback)
14. [Appendix: Master Plan References](#14-appendix-master-plan-references)
15. [PR #36: Documentation & Release (v2.9.4)](#15-pr-36-documentation--release-v294) *(NEW)*

---

## 1. Executive Summary

v2.9 is a **distribution and adoption release** with three major features from the master plan, plus activation of deprecation warnings:

| Feature | Type | Purpose |
|---------|------|---------|
| **install.py Bootstrap** | Distro | Single-file Python installer with SHA256 verification |
| **Schema Versioning** | Arch | Forward compatibility for V3 migration |
| **Curation Levels** | Growth | Lower adoption barrier with tiered validation |
| **Deprecation Warnings** | UX | Prepare users for V3 breaking changes |

**Why Now:** V2.8 established clean architecture (SessionContext, unified CLI). V2.9 makes Ontos easier to adopt and prepares the schema for V3.0's breaking changes.

**Risk Level:** HIGH — Four features is significant scope; install.py has security implications; schema versioning requires careful migration design. (Updated per LLM Review Board feedback)

**Current State:** v2.9.3 stable (install.py + warnings complete)
**Target State:** v2.9.4 release (Documentation & Final Polish)

---

## 2. Feature 1: install.py Bootstrap

### 2.1 Context & Rationale

**From Master Plan (Section II):**
> **v2.9 install.py Bootstrap** (Distro): Single-file Python installer (curl-bootstrapped). Bridge — simulates V3 ease without PyPI overhead.
>
> **Watch-out (Gemini):** Security Risk. Must verify checksums (SHA256) of downloaded assets. Must be idempotent (safe to run twice).

**Status:** ✅ IMPLEMENTED in v2.9.3 (PR #35)
1. Clone entire Project-Ontos repo
2. Copy `.ontos/` folder manually
3. Run `python3 ontos_init.py`

This friction hurts adoption. Users want:
```bash
# Use tag-pinned URL for reproducibility (per Codex Round 2)
curl -O https://raw.githubusercontent.com/ohjona/Project-Ontos/v2.9.0/install.py
python3 install.py
```

### 2.2 Design: install.py Architecture

**File Location:** `/install.py` (project root, committed to repo)

**User Flow:**
```bash
# Step 1: Download installer (tag-pinned for reproducibility, per Codex Round 2)
curl -sO https://raw.githubusercontent.com/ohjona/Project-Ontos/v2.9.0/install.py

# Step 2: Run installer
python3 install.py

# Step 3: (Optional) Remove installer
rm install.py
```

**What install.py Does:**

```
┌─────────────────────────────────────────────────────────────┐
│                      install.py                             │
├─────────────────────────────────────────────────────────────┤
│ 1. Check Python version (≥3.9)                              │
│ 2. Detect existing installation                             │
│    ├─ If exists: prompt for --upgrade or exit              │
│    └─ If fresh: continue                                    │
│ 3. Download checksums.json from GitHub                      │
│ 4. Download ontos-bundle.tar.gz from GitHub Releases        │
│ 5. Verify SHA256 checksum                                   │
│    ├─ If match: continue                                    │
│    └─ If mismatch: ABORT with security warning             │
│ 6. Extract bundle to current directory                      │
│    ├─ .ontos/                                               │
│    ├─ ontos.py                                              │
│    ├─ ontos_init.py                                         │
│    └─ docs/reference/Ontos_Agent_Instructions.md           │
│ 7. Run initialization (equivalent to ontos_init.py)         │
│ 8. Print success message with next steps                    │
└─────────────────────────────────────────────────────────────┘
```

### 2.3 Security Model

**Threat Model:**
- Man-in-the-middle attack could replace bundle
- Compromised GitHub release could contain malware
- User could run stale install.py with known vulnerabilities

**Mitigations:**

1. **SHA256 Verification via External checksums.json (REQUIRED)**

   *Updated per LLM Review Board feedback (Claude, Codex, Gemini all agreed)*

   ```python
   def fetch_checksum(version: str) -> str:
       """Fetch checksum from GitHub (tag-aligned, not main).

       Per Codex Round 3: checksums.json must be fetched from the same
       tag as the installer for reproducibility.
       """
       # Tag-aligned URL for reproducibility (per Codex R3)
       url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/v{version}/checksums.json"
       with urllib.request.urlopen(url, timeout=10) as response:
           checksums = json.loads(response.read())
       return checksums.get(version)
   ```

   - Checksums stored in `checksums.json` at repo root (decoupled from install.py)
   - **Fetched from the same tag as the version being installed** (per Codex Round 3)
   - Bundle downloaded, hashed locally, compared against fetched checksum
   - Mismatch = immediate abort with clear error

   **Why external vs embedded:** Embedding checksums creates a chicken-and-egg problem during releases (install.py is part of the bundle being checksummed). External checksums decouple the installer from the release workflow.

   **Why tag-aligned (v1.3.0):** Fetching from `main` breaks reproducibility—if checksums.json changes on main after a release, old installers could fail or verify against wrong checksums.

2. **HTTPS Only**
   - All downloads over HTTPS
   - No fallback to HTTP

3. **Version Pinning**
   - install.py downloads specific version (default: latest)
   - User can specify: `python3 install.py --version 2.9.0`
   - `--latest` flag fetches actual latest from GitHub Releases API (not stale embedded default)

4. **Integrity Check on Extraction**
   - After extraction, verify expected files exist
   - Check file count matches manifest

5. **Retry Logic with Exponential Backoff**

   *Added per LLM Review Board feedback (Claude)*

   ```python
   def download_with_retry(url: str, dest: Path, max_retries: int = 3) -> bool:
       for attempt in range(max_retries):
           try:
               urllib.request.urlretrieve(url, dest)
               return True
           except urllib.error.URLError as e:
               if attempt < max_retries - 1:
                   log(f"Retry {attempt + 1}/{max_retries}...")
                   time.sleep(2 ** attempt)  # Exponential backoff
               else:
                   log(f"Download failed after {max_retries} attempts: {e}", "error")
                   return False
   ```

#### Integrity Scope Note *(Added per Codex Round 2)*

*Explicit documentation of what this security model protects against and what it does NOT protect against.*

**Protected Against:**
- CDN/MITM tampering (bundle modified in transit)
- Corrupted downloads (network issues, partial downloads)
- Accidental version mismatch (wrong bundle for version)

**NOT Protected Against:**
- Repository compromise (attacker with push access can modify both checksums.json and bundle)
- Malicious maintainer (insider threat)
- DNS hijacking pointing to attacker-controlled GitHub mirror

**Future Enhancement (v3.0):** Cryptographic signing with GPG/minisign would protect against repository compromise by requiring an offline maintainer key. This is deferred to v3.0 when PyPI distribution (with trusted publishing) is adopted.

### 2.4 Implementation: install.py

```python
#!/usr/bin/env python3
"""Ontos Installer - Single-file bootstrap for Project Ontos.

Usage:
    curl -sO https://raw.githubusercontent.com/ohjona/Project-Ontos/v2.9.0/install.py
    python3 install.py

Options:
    --version VERSION   Install specific version (default: latest)
    --upgrade           Upgrade existing installation
    --check             Verify installation integrity without changes
    --help              Show this help message

Security:
    This installer verifies SHA256 checksums before extraction.
    If verification fails, installation is aborted immediately.

Requirements:
    Python 3.9+
    Internet connection (HTTPS)
"""

import hashlib
import json
import os
import sys
import tarfile
import tempfile
import urllib.request
from pathlib import Path

# =============================================================================
# CONFIGURATION
# =============================================================================

INSTALLER_VERSION = "1.0.0"
MIN_PYTHON_VERSION = (3, 9)

GITHUB_REPO = "ohjona/Project-Ontos"
GITHUB_RAW_URL = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main"
GITHUB_RELEASES_URL = f"https://github.com/{GITHUB_REPO}/releases/download"
GITHUB_API_URL = f"https://api.github.com/repos/{GITHUB_REPO}"

# Checksums are fetched from checksums.json (not embedded)
# This avoids the chicken-and-egg problem during releases
# Note: URL is constructed per-version in fetch_checksums() for tag alignment

# Default version (can be overridden with --latest to fetch from API)
DEFAULT_VERSION = "2.9.0"

# Fallback expected files (used only if manifest.json is missing)
# Per Codex R3: bundles should include manifest.json for version-aware verification
EXPECTED_FILES_FALLBACK = [
    ".ontos/scripts/ontos_lib.py",
    ".ontos/scripts/ontos_config_defaults.py",
    ".ontos/scripts/ontos/core/context.py",
    "ontos.py",
    "ontos_init.py",
]

# Bundle manifest path (included in bundle for version-aware verification)
MANIFEST_PATH = ".ontos/manifest.json"

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def log(message: str, level: str = "info") -> None:
    """Print a log message with appropriate prefix."""
    prefixes = {
        "info": "[*]",
        "success": "[+]",
        "warning": "[!]",
        "error": "[X]",
    }
    print(f"{prefixes.get(level, '[*]')} {message}")


def check_python_version() -> bool:
    """Verify Python version meets minimum requirements."""
    current = sys.version_info[:2]
    if current < MIN_PYTHON_VERSION:
        log(f"Python {MIN_PYTHON_VERSION[0]}.{MIN_PYTHON_VERSION[1]}+ required. "
            f"You have {current[0]}.{current[1]}.", "error")
        return False
    return True


def sha256_file(filepath: Path) -> str:
    """Calculate SHA256 hash of a file."""
    sha256 = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()


def download_file(url: str, dest: Path, description: str = "", max_retries: int = 3) -> bool:
    """Download a file from URL with retry logic."""
    for attempt in range(max_retries):
        try:
            log(f"Downloading {description or url}...")
            urllib.request.urlretrieve(url, dest)
            return True
        except urllib.error.URLError as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                log(f"Download failed, retrying in {wait_time}s... ({attempt + 1}/{max_retries})", "warning")
                import time
                time.sleep(wait_time)
            else:
                log(f"Download failed after {max_retries} attempts: {e}", "error")
                return False
    return False


def detect_existing_installation() -> dict:
    """Detect if Ontos is already installed.

    Per Codex Round 3: Also detects incomplete installations via sentinel file.
    """
    cwd = Path.cwd()
    result = {
        "installed": False,
        "incomplete": False,  # Added per Codex R3
        "version": None,
        "files": [],
    }

    ontos_dir = cwd / ".ontos"
    if ontos_dir.exists():
        result["installed"] = True
        result["files"].append(".ontos/")

        # Check for incomplete installation sentinel (per Codex R3)
        sentinel = ontos_dir / ".install_incomplete"
        if sentinel.exists():
            result["incomplete"] = True

        # Try to read version
        defaults_file = ontos_dir / "scripts" / "ontos_config_defaults.py"
        if defaults_file.exists():
            content = defaults_file.read_text()
            for line in content.split('\n'):
                if 'ONTOS_VERSION' in line and '=' in line:
                    # Extract version string
                    version = line.split('=')[1].strip().strip('"\'')
                    result["version"] = version
                    break

    if (cwd / "ontos.py").exists():
        result["files"].append("ontos.py")
    if (cwd / "ontos_init.py").exists():
        result["files"].append("ontos_init.py")

    return result


# =============================================================================
# MAIN INSTALLATION LOGIC
# =============================================================================

def fetch_checksums(version: str) -> dict:
    """Fetch checksums from GitHub (tag-aligned for reproducibility).

    Per Codex Round 3: checksums.json is fetched from the same tag as
    the version being installed, not from main. This ensures reproducibility.
    """
    # Tag-aligned URL (per Codex R3)
    checksums_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/v{version}/checksums.json"
    try:
        log("Fetching checksums...")
        with urllib.request.urlopen(checksums_url, timeout=10) as response:
            return json.loads(response.read().decode('utf-8'))
    except (urllib.error.URLError, json.JSONDecodeError) as e:
        log(f"Failed to fetch checksums: {e}", "error")
        return {}


def verify_checksum(filepath: Path, version: str) -> bool:
    """Verify SHA256 checksum of downloaded bundle."""
    # Fetch checksums from tag-aligned source (per Codex R3)
    checksums = fetch_checksums(version)
    expected = checksums.get(version)

    if not expected:
        log(f"No checksum found for version {version}. "
            "This may be a development version.", "warning")
        response = input("Continue without verification? [y/N]: ")
        return response.lower() == 'y'

    actual = sha256_file(filepath)

    if actual != expected:
        log("SECURITY WARNING: Checksum verification FAILED!", "error")
        log(f"Expected: {expected}", "error")
        log(f"Actual:   {actual}", "error")
        log("The downloaded file may have been tampered with.", "error")
        log("Installation aborted for your safety.", "error")
        return False

    log("Checksum verified successfully.", "success")
    return True


def extract_bundle(bundle_path: Path, dest_dir: Path) -> bool:
    """Extract the tar.gz bundle to destination directory."""
    try:
        log("Extracting files...")
        with tarfile.open(bundle_path, 'r:gz') as tar:
            for member in tar.getmembers():
                # Security: check for path traversal attacks
                if member.name.startswith('/') or '..' in member.name:
                    log(f"Suspicious path in archive: {member.name}", "error")
                    return False
                # Security: check for symlink attacks (per Claude Round 2)
                if member.issym() or member.islnk():
                    log(f"Symlinks not allowed in archive: {member.name}", "error")
                    return False

            tar.extractall(dest_dir)
        return True
    except tarfile.TarError as e:
        log(f"Extraction failed: {e}", "error")
        return False


def verify_extraction(dest_dir: Path) -> bool:
    """Verify expected files exist after extraction.

    Per Codex Round 3: Uses manifest.json from bundle if present,
    falls back to static list for compatibility with older bundles.
    """
    manifest_file = dest_dir / MANIFEST_PATH

    # Try manifest-based verification first (per Codex R3)
    if manifest_file.exists():
        try:
            with open(manifest_file) as f:
                manifest = json.load(f)
            expected_files = manifest.get("files", [])
            log(f"Using bundle manifest (version {manifest.get('version', 'unknown')})")
        except (json.JSONDecodeError, IOError) as e:
            log(f"Warning: manifest.json invalid, using fallback: {e}", "warning")
            expected_files = EXPECTED_FILES_FALLBACK
    else:
        # Fallback for older bundles without manifest
        log("No manifest.json found, using fallback file list", "warning")
        expected_files = EXPECTED_FILES_FALLBACK

    missing = []
    for expected in expected_files:
        if not (dest_dir / expected).exists():
            missing.append(expected)

    if missing:
        log(f"Missing expected files: {missing}", "error")
        return False

    log("All expected files present.", "success")
    return True


def run_initialization() -> bool:
    """Run ontos_init.py to complete setup."""
    log("Running initialization...")

    # Import and run ontos_init
    init_path = Path.cwd() / "ontos_init.py"
    if not init_path.exists():
        log("ontos_init.py not found after extraction.", "error")
        return False

    # Run as subprocess to avoid import issues
    import subprocess
    result = subprocess.run(
        [sys.executable, str(init_path), "--non-interactive"],
        capture_output=True,
        text=True
    )

    if result.returncode != 0:
        log(f"Initialization failed: {result.stderr}", "error")
        return False

    return True


def install(version: str = None, upgrade: bool = False) -> int:
    """Main installation function.

    Returns:
        0 on success, 1 on failure
    """
    version = version or DEFAULT_VERSION

    log(f"Ontos Installer v{INSTALLER_VERSION}")
    log(f"Installing Ontos v{version}...")

    # Step 1: Check Python version
    if not check_python_version():
        return 1

    # Step 2: Detect existing installation
    existing = detect_existing_installation()
    if existing["installed"]:
        # Handle incomplete installation (per Codex R3)
        if existing["incomplete"]:
            log("Previous installation was incomplete.", "warning")
            log("Cleaning up and retrying...")
            # Remove sentinel and continue with upgrade
            sentinel = Path.cwd() / ".ontos" / ".install_incomplete"
            sentinel.unlink(missing_ok=True)
            upgrade = True  # Force upgrade mode for incomplete installs

        if not upgrade:
            log(f"Ontos v{existing['version']} already installed.", "warning")
            log("Use --upgrade to upgrade, or remove existing installation first.")
            log(f"Existing files: {existing['files']}")
            return 1
        else:
            log(f"Upgrading from v{existing['version']} to v{version}...")

    # Step 3: Download bundle
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir = Path(tmpdir)
        bundle_path = tmpdir / "ontos-bundle.tar.gz"

        bundle_url = f"{GITHUB_RELEASES_URL}/v{version}/ontos-bundle.tar.gz"
        if not download_file(bundle_url, bundle_path, f"Ontos v{version} bundle"):
            log("Failed to download bundle. Check your internet connection.", "error")
            log(f"URL: {bundle_url}", "error")
            return 1

        # Step 4: Verify checksum
        if not verify_checksum(bundle_path, version):
            return 1

        # Step 5: Extract bundle
        if not extract_bundle(bundle_path, Path.cwd()):
            return 1

    # Step 6: Verify extraction
    if not verify_extraction(Path.cwd()):
        return 1

    # Step 7: Run initialization with sentinel pattern (per Gemini Round 2)
    # Sentinel file marks installation as incomplete until init succeeds
    sentinel = Path.cwd() / ".ontos" / ".install_incomplete"
    sentinel.parent.mkdir(parents=True, exist_ok=True)
    sentinel.touch()

    try:
        if not run_initialization():
            log("Extraction complete but initialization failed.", "warning")
            log("Run 'python3 ontos_init.py' manually to complete setup.")
            return 1
        # Remove sentinel on success
        sentinel.unlink(missing_ok=True)
    except Exception as e:
        log(f"Initialization failed: {e}", "error")
        log("Installation marked as incomplete. Run 'python3 ontos_init.py' to retry.")
        return 1

    # Success!
    log("Ontos installed successfully!", "success")
    log("")
    log("Next steps:")
    log("  1. Tell your AI agent: 'Activate Ontos'")
    log("  2. Create your first session log: python3 ontos.py log -e feature")
    log("  3. Read the manual: docs/reference/Ontos_Manual.md")
    log("")
    log(f"Installed version: {version}")

    return 0


def check_installation() -> int:
    """Verify integrity of existing installation."""
    log("Checking installation integrity...")

    existing = detect_existing_installation()
    if not existing["installed"]:
        log("Ontos is not installed in this directory.", "error")
        return 1

    log(f"Found Ontos v{existing['version']}")

    if verify_extraction(Path.cwd()):
        log("Installation integrity: OK", "success")
        return 0
    else:
        log("Installation integrity: FAILED", "error")
        log("Some files may be missing. Consider reinstalling with --upgrade.")
        return 1


# =============================================================================
# CLI ENTRY POINT
# =============================================================================

def fetch_latest_version() -> str:
    """Fetch latest version from GitHub Releases API (per Codex R3)."""
    try:
        log("Fetching latest version from GitHub...")
        with urllib.request.urlopen(f"{GITHUB_API_URL}/releases/latest", timeout=10) as response:
            data = json.loads(response.read().decode('utf-8'))
            version = data.get("tag_name", "").lstrip("v")
            if version:
                log(f"Latest version: {version}")
                return version
    except (urllib.error.URLError, json.JSONDecodeError) as e:
        log(f"Failed to fetch latest version: {e}", "warning")
    return DEFAULT_VERSION  # Fallback to embedded default


def main() -> int:
    """Parse arguments and run appropriate command."""
    args = sys.argv[1:]

    # Parse flags
    version = None
    upgrade = False
    check = False
    use_latest = False  # Added per Codex R3

    i = 0
    while i < len(args):
        arg = args[i]
        if arg in ('-h', '--help'):
            print(__doc__)
            return 0
        elif arg == '--version':
            if i + 1 < len(args):
                version = args[i + 1]
                i += 1
            else:
                log("--version requires a version number", "error")
                return 1
        elif arg == '--latest':
            # Fetch latest version from GitHub API (per Codex R3)
            use_latest = True
        elif arg == '--upgrade':
            upgrade = True
        elif arg == '--check':
            check = True
        else:
            log(f"Unknown argument: {arg}", "error")
            print(__doc__)
            return 1
        i += 1

    # Resolve version: explicit > --latest > default (per Codex R3)
    if version is None:
        if use_latest:
            version = fetch_latest_version()
        else:
            version = DEFAULT_VERSION

    if check:
        return check_installation()
    else:
        return install(version=version, upgrade=upgrade)


if __name__ == '__main__':
    sys.exit(main())
```

### 2.5 Release Bundle Creation

**New Script:** `.ontos/scripts/ontos_create_bundle.py`

This script creates the release bundle:

```python
#!/usr/bin/env python3
"""Create release bundle for Ontos distribution.

Usage:
    python3 .ontos/scripts/ontos_create_bundle.py --version 2.9.0

Creates:
    - ontos-bundle.tar.gz (for GitHub Releases)
    - checksums.json (for verification)
"""

import argparse
import datetime
import hashlib
import io
import json
import os
import tarfile
from pathlib import Path

BUNDLE_FILES = [
    ".ontos/",
    "ontos.py",
    "ontos_init.py",
    "docs/reference/Ontos_Agent_Instructions.md",
    "docs/reference/Ontos_Manual.md",
    "docs/reference/Common_Concepts.md",
]

EXCLUDE_PATTERNS = [
    "__pycache__",
    ".pytest_cache",
    "*.pyc",
    ".DS_Store",
]


def should_exclude(path: str) -> bool:
    """Check if path should be excluded from bundle."""
    for pattern in EXCLUDE_PATTERNS:
        if pattern.startswith("*"):
            if path.endswith(pattern[1:]):
                return True
        elif pattern in path:
            return True
    return False


def create_manifest(version: str, files: list) -> dict:
    """Create manifest.json for version-aware verification (per Codex R3)."""
    return {
        "version": version,
        "created": datetime.datetime.utcnow().isoformat() + "Z",
        "files": files,
    }


def create_bundle(version: str, output_dir: Path) -> Path:
    """Create the release bundle with manifest.json (per Codex R3)."""
    bundle_name = "ontos-bundle.tar.gz"
    bundle_path = output_dir / bundle_name

    # Collect all files that will be in the bundle
    included_files = []

    with tarfile.open(bundle_path, "w:gz") as tar:
        for item in BUNDLE_FILES:
            item_path = Path(item)
            if not item_path.exists():
                print(f"Warning: {item} not found, skipping")
                continue

            if item_path.is_dir():
                for root, dirs, files in os.walk(item_path):
                    # Filter excluded directories
                    dirs[:] = [d for d in dirs if not should_exclude(d)]

                    for file in files:
                        if not should_exclude(file):
                            filepath = Path(root) / file
                            tar.add(filepath, arcname=str(filepath))
                            included_files.append(str(filepath))
            else:
                tar.add(item_path)
                included_files.append(str(item_path))

        # Add manifest.json to bundle (per Codex R3)
        manifest = create_manifest(version, included_files)
        manifest_content = json.dumps(manifest, indent=2).encode('utf-8')

        manifest_info = tarfile.TarInfo(name=".ontos/manifest.json")
        manifest_info.size = len(manifest_content)
        tar.addfile(manifest_info, io.BytesIO(manifest_content))
        print(f"Added manifest.json with {len(included_files)} files")

    print(f"Created: {bundle_path}")
    return bundle_path


def calculate_checksum(filepath: Path) -> str:
    """Calculate SHA256 checksum of file."""
    sha256 = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            sha256.update(chunk)
    return sha256.hexdigest()


def main():
    parser = argparse.ArgumentParser(description="Create Ontos release bundle")
    parser.add_argument("--version", required=True, help="Version number (e.g., 2.9.0)")
    parser.add_argument("--output", default="dist", help="Output directory")
    args = parser.parse_args()

    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)

    # Create bundle
    bundle_path = create_bundle(args.version, output_dir)

    # Calculate checksum
    checksum = calculate_checksum(bundle_path)
    print(f"SHA256: {checksum}")

    # Write checksums.json
    checksums_path = output_dir / "checksums.json"
    checksums = {}
    if checksums_path.exists():
        checksums = json.loads(checksums_path.read_text())
    checksums[args.version] = checksum
    checksums_path.write_text(json.dumps(checksums, indent=2))
    print(f"Updated: {checksums_path}")

    # Print instructions
    print("\n" + "="*60)
    print("RELEASE INSTRUCTIONS:")
    print("="*60)
    print(f"1. Update CHECKSUMS in install.py with:")
    print(f'   "{args.version}": "{checksum}",')
    print(f"2. Create GitHub Release v{args.version}")
    print(f"3. Upload {bundle_path} to the release")
    print("="*60)


if __name__ == "__main__":
    main()
```

### 2.6 Idempotency & Upgrade Requirements

Per Gemini's watch-out, install.py MUST be idempotent. Per Codex and Gemini feedback, upgrade must include proper config merge and rollback.

| Scenario | Behavior |
|----------|----------|
| Fresh install | Full installation |
| Same version exists | Exit with message (use --upgrade) |
| Older version exists | Exit with message (use --upgrade) |
| --upgrade flag | Backup → Install → Merge config → Rollback on failure |
| Partial installation | Detect and repair |
| Init failure | Rollback extracted files |

**Config Merge on Upgrade (Updated per LLM Review Board):**

*Gemini's insight: "What if the new version introduces new, essential config variables? Simply restoring the old file would mean these new settings are missing."*

```python
def upgrade():
    # 1. Create full backup of .ontos/ and ontos.py
    backup_dir = create_backup()

    try:
        # 2. Read user's old config values
        old_config = read_user_config()

        # 3. Remove old files
        remove_old_installation()

        # 4. Install new version (includes new default config)
        install()

        # 5. MERGE: Apply user's old settings to new default config
        new_config = read_default_config()
        merged_config = merge_configs(new_config, old_config)
        write_user_config(merged_config)

        log("Config merged: your customizations preserved + new defaults added", "success")

    except Exception as e:
        # 6. ROLLBACK on any failure
        log(f"Upgrade failed: {e}", "error")
        log("Rolling back to previous installation...", "warning")
        restore_from_backup(backup_dir)
        return 1

    # 7. Clean up backup on success
    cleanup_backup(backup_dir)
    return 0


def merge_configs(new_config: dict, old_config: dict) -> dict:
    """Merge old user config into new default config.

    Strategy:
    - Start with new config (has all new variables with defaults)
    - Override with user's old values (preserve customizations)
    - Result: new variables + user customizations
    """
    merged = new_config.copy()
    for key, value in old_config.items():
        if key in merged:
            merged[key] = value  # Preserve user's customization
        # Note: old keys not in new config are dropped (deprecated)
    return merged
```

**Rollback on Init Failure (Added per Claude's feedback):**

```python
def install(...):
    # ... extraction ...

    # Mark installation as incomplete
    sentinel = Path.cwd() / ".ontos" / ".install_incomplete"
    sentinel.touch()

    try:
        run_initialization()
        sentinel.unlink()  # Remove sentinel on success
    except Exception as e:
        log("Initialization failed. Rolling back extracted files...", "error")
        rollback_extraction()
        return 1
```

---

## 3. Feature 2: Schema Versioning

### 3.1 Context & Rationale

**From Master Plan (Section II):**
> **v2.9 Schema Versioning** (Arch): ontos_schema: 3.0 in frontmatter. Migration tools.
>
> **Watch-out (Claude):** Define explicit migration path. What happens if V2 script reads V3 data? (Should fail gracefully).

**Problem:** V3.0 will introduce breaking changes:
- Typed edges (`implements`, `tests`, `deprecates`)
- New frontmatter fields
- Potentially different validation rules

Without schema versioning, we cannot:
- Detect incompatible documents
- Provide migration tooling
- Maintain backwards compatibility

### 3.2 Schema Version Design

**Field:** `ontos_schema` (optional in v2.9, required in v3.0)

**Version Format:** Major.Minor (e.g., `2.0`, `2.1`, `3.0`)

**Schema History:**

| Schema Version | Ontos Version | New Fields | Breaking Changes |
|----------------|---------------|------------|------------------|
| 1.0 | v1.x | id, type, depends_on | (baseline) |
| 2.0 | v2.0-v2.6 | status, event_type, impacts, concepts | log type added |
| 2.1 | v2.7+ | describes, describes_verified | (none) |
| **2.2** | **v2.9+** | **ontos_schema, curation_level** | (none) |
| 3.0 | v3.0+ | edge_type, edge_target | typed edges |

#### Schema Specification Table *(Added per Codex Round 2)*

*Explicit schema contracts with required/optional fields and validation rules. Inference is limited to legacy documents without `ontos_schema` field.*

| Schema | Required Fields | Optional Fields | Validation Rules |
|--------|-----------------|-----------------|------------------|
| **1.0** | `id` | `type`, `depends_on` | ID must be unique |
| **2.0** | `id`, `type` | `status`, `depends_on`, `concepts`, `event_type`, `impacts` | Type must be valid (kernel/strategy/product/atom/log) |
| **2.1** | `id`, `type`, `status` | `depends_on`, `concepts`, `describes`, `describes_verified` | + describes validation for log type |
| **2.2** | `id`, `type`, `status` | `ontos_schema`, `curation_level`, `depends_on`, `concepts`, `describes` | + curation level validation |
| **3.0** | `id`, `type`, `status`, `ontos_schema` | `implements`, `tests`, `deprecates`, `depends_on`, `concepts` | + typed edge validation |

**Inference Rules (Legacy Only):**
- If `ontos_schema` is present → use that version (explicit)
- If `ontos_schema` is absent → infer from fields:
  - `implements`/`tests` present → 3.0
  - `describes` present → 2.1
  - `event_type`/`impacts` present → 2.0
  - Otherwise → 1.0
- Post-migration: all documents should have explicit `ontos_schema`

**Future Version Handling:**
- v2.9 scripts reading v3.0+ documents → Error with message: "Document requires Ontos v3.0+. Run: python3 ontos.py update"
- Unknown schema versions (e.g., 4.0) → Error with upgrade guidance

### 3.3 Frontmatter Examples

**V2.9 Document (schema 2.2):**
```yaml
---
id: my_feature
type: product
status: active
depends_on: [mission, v2_strategy]
ontos_schema: "2.2"
curation_level: 2
---
```

**V3.0 Document (schema 3.0):**
```yaml
---
id: my_feature
type: product
status: active
depends_on: [mission, v2_strategy]
ontos_schema: "3.0"
implements: [feature_request_123]
tests: [test_my_feature]
---
```

### 3.4 Validation Rules

**Schema Version Detection:**

```python
def detect_schema_version(frontmatter: dict) -> str:
    """Detect schema version from frontmatter.

    Returns:
        Schema version string (e.g., "2.2", "3.0")
    """
    # Explicit version takes precedence
    if 'ontos_schema' in frontmatter:
        return frontmatter['ontos_schema']

    # Infer from fields present
    if 'implements' in frontmatter or 'tests' in frontmatter:
        return "3.0"
    if 'describes' in frontmatter or 'describes_verified' in frontmatter:
        return "2.1"
    if 'event_type' in frontmatter or 'impacts' in frontmatter:
        return "2.0"

    return "1.0"  # Legacy
```

**Compatibility Matrix:**

| Script Version | Reads 1.0 | Reads 2.0 | Reads 2.1 | Reads 2.2 | Reads 3.0 |
|----------------|-----------|-----------|-----------|-----------|-----------|
| v2.8 scripts | Yes | Yes | Yes | Warn* | Error |
| v2.9 scripts | Yes | Yes | Yes | Yes | Error |
| v3.0 scripts | Yes | Yes | Yes | Yes | Yes |

*v2.8 seeing `ontos_schema: "2.2"` should warn but continue (unknown field)

### 3.5 Implementation: Schema Module

> **✅ IMPLEMENTED in PR #31** (merged 2025-12-22)
>
> The actual implementation differs from the code below in several ways.
> See [Section 3.5.1 Actual API](#351-actual-api-pr-31) for the real interface.

**New File:** `.ontos/scripts/ontos/core/schema.py`

```python
"""Schema versioning and migration utilities.

This module handles:
- Schema version detection
- Compatibility checking
- Migration between schema versions
"""

from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Optional, Tuple
from pathlib import Path

# Current schema version (what v2.9 scripts produce)
CURRENT_SCHEMA_VERSION = "2.2"

# Minimum schema version we can read
MIN_READABLE_SCHEMA = "1.0"

# Maximum schema version we understand
MAX_READABLE_SCHEMA = "2.2"


class SchemaCompatibility(Enum):
    """Schema compatibility status."""
    COMPATIBLE = "compatible"
    UPGRADEABLE = "upgradeable"  # Can auto-upgrade
    INCOMPATIBLE = "incompatible"  # Cannot read


@dataclass
class SchemaInfo:
    """Information about a document's schema."""
    version: str
    explicit: bool  # True if ontos_schema field present
    compatibility: SchemaCompatibility
    migration_needed: bool
    issues: List[str]


def parse_version(version_str: str) -> Tuple[int, int]:
    """Parse version string to tuple.

    Args:
        version_str: Version string like "2.1" or "3.0"

    Returns:
        Tuple of (major, minor)

    Raises:
        ValueError: If version string is empty or invalid format
    """
    # Validation added per Claude Round 2
    if not version_str:
        raise ValueError("Empty version string")

    parts = version_str.split('.')
    try:
        major = int(parts[0])
        minor = int(parts[1]) if len(parts) > 1 else 0
        return (major, minor)
    except (ValueError, IndexError) as e:
        raise ValueError(f"Invalid version format: {version_str}") from e


def detect_schema_version(frontmatter: dict) -> str:
    """Detect schema version from frontmatter fields.

    Priority:
    1. Explicit ontos_schema field
    2. Inference from fields present
    3. Default to 1.0 (legacy)
    """
    if 'ontos_schema' in frontmatter:
        return str(frontmatter['ontos_schema'])

    # V3.0 indicators
    if any(f in frontmatter for f in ['implements', 'tests', 'deprecates', 'edge_type']):
        return "3.0"

    # V2.2 indicators
    if 'curation_level' in frontmatter:
        return "2.2"

    # V2.1 indicators
    if any(f in frontmatter for f in ['describes', 'describes_verified']):
        return "2.1"

    # V2.0 indicators
    if any(f in frontmatter for f in ['event_type', 'impacts', 'concepts']):
        return "2.0"

    # V1.0 baseline
    return "1.0"


def check_compatibility(schema_version: str) -> SchemaCompatibility:
    """Check if we can read a document with given schema version."""
    version = parse_version(schema_version)
    min_version = parse_version(MIN_READABLE_SCHEMA)
    max_version = parse_version(MAX_READABLE_SCHEMA)
    current = parse_version(CURRENT_SCHEMA_VERSION)

    if version > max_version:
        return SchemaCompatibility.INCOMPATIBLE

    if version < current:
        return SchemaCompatibility.UPGRADEABLE

    return SchemaCompatibility.COMPATIBLE


def analyze_document(frontmatter: dict) -> SchemaInfo:
    """Analyze a document's schema status."""
    version = detect_schema_version(frontmatter)
    explicit = 'ontos_schema' in frontmatter
    compatibility = check_compatibility(version)

    issues = []
    migration_needed = False

    if compatibility == SchemaCompatibility.INCOMPATIBLE:
        issues.append(f"Schema {version} is not supported by this version of Ontos")
    elif compatibility == SchemaCompatibility.UPGRADEABLE:
        migration_needed = True
        if not explicit:
            issues.append(f"Missing ontos_schema field (detected as {version})")

    return SchemaInfo(
        version=version,
        explicit=explicit,
        compatibility=compatibility,
        migration_needed=migration_needed,
        issues=issues,
    )


def migrate_frontmatter(
    frontmatter: dict,
    from_version: str,
    to_version: str
) -> dict:
    """Migrate frontmatter from one schema version to another.

    Returns:
        Updated frontmatter dict
    """
    result = frontmatter.copy()

    from_v = parse_version(from_version)
    to_v = parse_version(to_version)

    if from_v >= to_v:
        # No migration needed (downgrade not supported)
        return result

    # Apply migrations in order
    if from_v < (2, 2) <= to_v:
        # Upgrade to 2.2: add schema field
        result['ontos_schema'] = "2.2"

        # Add default curation_level if missing
        if 'curation_level' not in result:
            # Infer from existing fields
            if result.get('depends_on') or result.get('concepts'):
                result['curation_level'] = 2
            elif result.get('status') == 'pending_curation':
                result['curation_level'] = 1
            else:
                result['curation_level'] = 0

    return result


def serialize_frontmatter(fm: dict) -> str:
    """Serialize frontmatter dict to YAML-like string using stdlib only.

    NOTE: This is a simplified serializer for frontmatter.
    It does NOT preserve comments (that would require ruamel.yaml).
    Comment preservation is deferred to v3.0 when we have PyPI dependencies.

    Updated per LLM Review Board feedback (Claude) - no yaml import allowed in v2.x.
    """
    lines = []
    for key, value in fm.items():
        if value is None:
            continue
        elif isinstance(value, list):
            if not value:
                lines.append(f"{key}: []")
            elif all(isinstance(v, str) and ' ' not in v for v in value):
                # Simple list: [item1, item2]
                items = ', '.join(str(v) for v in value)
                lines.append(f"{key}: [{items}]")
            else:
                # Multi-line list
                lines.append(f"{key}:")
                for item in value:
                    lines.append(f"  - {item}")
        elif isinstance(value, bool):
            lines.append(f"{key}: {'true' if value else 'false'}")
        elif isinstance(value, (int, float)):
            lines.append(f"{key}: {value}")
        elif isinstance(value, str):
            if '\n' in value:
                # Multi-line string
                lines.append(f"{key}: |")
                for line in value.split('\n'):
                    lines.append(f"  {line}")
            elif ':' in value or '#' in value or value.startswith('"'):
                # Quote strings with special chars
                lines.append(f'{key}: "{value}"')
            else:
                lines.append(f"{key}: {value}")
        else:
            lines.append(f"{key}: {value}")
    return '\n'.join(lines)
```

#### 3.5.1 Actual API (PR #31)

The implementation in PR #31 differs from the theoretical code above. **PR #32 and beyond should use this actual API:**

**Constants:**
```python
CURRENT_SCHEMA_VERSION = "2.2"
MIN_READABLE_SCHEMA = "1.0"
MAX_READABLE_SCHEMA = "2.2"
SCHEMA_DEFINITIONS: Dict[str, Dict[str, List[str]]]  # All schema versions
SCHEMA_TOOL_REQUIREMENTS: Dict[str, str]  # Schema → min tool version
```

**Classes:**
```python
class SchemaCompatibility(Enum):
    COMPATIBLE = "compatible"      # Full read/write
    READ_ONLY = "read_only"        # Can read, may not preserve all fields
    INCOMPATIBLE = "incompatible"  # Cannot handle

@dataclass
class SchemaCheckResult:
    compatibility: SchemaCompatibility
    document_version: str
    tool_version: str
    message: str
```

**Functions:**
```python
def parse_version(version_str: str) -> Tuple[int, int]
def detect_schema_version(frontmatter: Dict[str, Any]) -> str
def check_compatibility(doc_version: str, tool_version: str) -> SchemaCheckResult
def validate_frontmatter(frontmatter: Dict[str, Any], schema_version: Optional[str] = None) -> Tuple[bool, List[str]]
def serialize_frontmatter(fm: Dict[str, Any]) -> str
def add_schema_to_frontmatter(frontmatter: Dict[str, Any], schema_version: Optional[str] = None) -> Dict[str, Any]
def get_schema_info(version: str) -> Optional[Dict[str, List[str]]]
```

**Key Differences from Plan:**
| Aspect | Plan | Actual |
|--------|------|--------|
| Compatibility enum value | `UPGRADEABLE` | `READ_ONLY` |
| `check_compatibility()` | Single arg (schema_version) | Two args (doc_version, tool_version) |
| Return type | `SchemaCompatibility` | `SchemaCheckResult` (richer) |
| `analyze_document()` | Included | Not implemented (not needed) |
| `migrate_frontmatter()` | Included | Not implemented (handled in migration script) |

---

### 3.6 Migration CLI Command

> **✅ IMPLEMENTED in PR #31** (merged 2025-12-22)
>
> Actual implementation: `.ontos/scripts/ontos_migrate_schema.py`
> CLI command: `python3 ontos.py migrate`

**New Command:** `ontos.py migrate`

```bash
# Check what needs migration
python3 ontos.py migrate --check

# Preview migrations (dry run)
python3 ontos.py migrate --dry-run

# Apply migrations
python3 ontos.py migrate --apply

# Migrate specific directory
python3 ontos.py migrate --apply --dirs docs .ontos-internal
```

**Implementation in ontos.py:**

Add to COMMANDS:
```python
'migrate': ('ontos_migrate_schema', 'Migrate documents to current schema'),
```

**New Script:** `.ontos/scripts/ontos_migrate_schema.py`

```python
#!/usr/bin/env python3
"""Migrate documents to current schema version.

Usage:
    python3 ontos.py migrate --check      # Show what needs migration
    python3 ontos.py migrate --dry-run    # Preview changes
    python3 ontos.py migrate --apply      # Apply migrations
"""

import argparse
import sys
from pathlib import Path

# Add scripts directory to path
SCRIPTS_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPTS_DIR))

from ontos.core.schema import (
    CURRENT_SCHEMA_VERSION,
    SchemaCompatibility,
    analyze_document,
    migrate_frontmatter,
)
from ontos.core.frontmatter import parse_frontmatter
from ontos.core.context import SessionContext
from ontos.ui.output import OutputHandler


def scan_documents(docs_dir: Path) -> list:
    """Scan all markdown documents."""
    documents = []
    for md_file in docs_dir.rglob("*.md"):
        if '.ontos' in str(md_file) or 'archive' in str(md_file):
            continue

        try:
            frontmatter = parse_frontmatter(md_file)
            if frontmatter and 'id' in frontmatter:
                documents.append((md_file, frontmatter))
        except Exception:
            continue

    return documents


def check_migrations(documents: list, output: OutputHandler) -> dict:
    """Check which documents need migration."""
    results = {
        'compatible': [],
        'upgradeable': [],
        'incompatible': [],
    }

    for filepath, frontmatter in documents:
        info = analyze_document(frontmatter)

        if info.compatibility == SchemaCompatibility.COMPATIBLE:
            results['compatible'].append((filepath, info))
        elif info.compatibility == SchemaCompatibility.UPGRADEABLE:
            results['upgradeable'].append((filepath, info))
        else:
            results['incompatible'].append((filepath, info))

    return results


def apply_migration(
    filepath: Path,
    frontmatter: dict,
    ctx: SessionContext,
    output: OutputHandler,
    dry_run: bool = False
) -> bool:
    """Apply migration to a single file."""
    info = analyze_document(frontmatter)

    if not info.migration_needed:
        return True

    # Calculate new frontmatter
    new_frontmatter = migrate_frontmatter(
        frontmatter,
        info.version,
        CURRENT_SCHEMA_VERSION
    )

    # Read full file content
    content = filepath.read_text()

    # Find frontmatter boundaries
    lines = content.split('\n')
    if lines[0] != '---':
        output.error(f"Cannot migrate {filepath}: no frontmatter")
        return False

    end_idx = None
    for i, line in enumerate(lines[1:], 1):
        if line == '---':
            end_idx = i
            break

    if end_idx is None:
        output.error(f"Cannot migrate {filepath}: unclosed frontmatter")
        return False

    # Build new content using stdlib-only serialization
    # (Updated per LLM Review Board - no yaml dependency allowed in v2.x)
    new_yaml = serialize_frontmatter(new_frontmatter)
    new_content = '---\n' + new_yaml + '\n---\n' + '\n'.join(lines[end_idx+1:])

    if dry_run:
        output.info(f"Would migrate: {filepath}")
        output.detail(f"  Schema: {info.version} -> {CURRENT_SCHEMA_VERSION}")
        for issue in info.issues:
            output.detail(f"  Fix: {issue}")
    else:
        ctx.buffer_write(filepath, new_content)
        output.success(f"Migrated: {filepath}")

    return True


def main() -> int:
    parser = argparse.ArgumentParser(description="Migrate documents to current schema")
    parser.add_argument('--check', action='store_true', help="Show migration status")
    parser.add_argument('--dry-run', action='store_true', help="Preview changes")
    parser.add_argument('--apply', action='store_true', help="Apply migrations")
    parser.add_argument('--quiet', '-q', action='store_true', help="Quiet output")
    parser.add_argument('files', nargs='*', help="Specific files to migrate")
    args = parser.parse_args()

    output = OutputHandler(quiet=args.quiet)
    ctx = SessionContext.from_repo(Path.cwd())

    # Determine docs directory
    from ontos_config import DOCS_DIR
    docs_dir = Path(DOCS_DIR)

    # Scan documents
    if args.files:
        documents = []
        for f in args.files:
            filepath = Path(f)
            if filepath.exists():
                fm = parse_frontmatter(filepath)
                if fm:
                    documents.append((filepath, fm))
    else:
        documents = scan_documents(docs_dir)

    output.info(f"Scanned {len(documents)} documents")

    # Check migrations
    results = check_migrations(documents, output)

    if args.check or (not args.apply and not args.dry_run):
        # Just show status
        output.plain(f"\nSchema Status (current: {CURRENT_SCHEMA_VERSION}):")
        output.success(f"  Compatible:   {len(results['compatible'])}")
        output.warning(f"  Upgradeable:  {len(results['upgradeable'])}")
        output.error(f"  Incompatible: {len(results['incompatible'])}")

        if results['upgradeable']:
            output.plain("\nDocuments needing migration:")
            for filepath, info in results['upgradeable']:
                output.detail(f"  {filepath} (schema {info.version})")

        if results['incompatible']:
            output.plain("\nIncompatible documents (cannot migrate):")
            for filepath, info in results['incompatible']:
                output.detail(f"  {filepath} (schema {info.version})")
                for issue in info.issues:
                    output.detail(f"    - {issue}")

        return 0

    # Apply or dry-run migrations
    success_count = 0
    error_count = 0

    for filepath, frontmatter in results['upgradeable']:
        if apply_migration(filepath, frontmatter, ctx, output, dry_run=args.dry_run):
            success_count += 1
        else:
            error_count += 1

    if not args.dry_run and success_count > 0:
        try:
            modified = ctx.commit()
            output.success(f"\nMigrated {len(modified)} files")
        except Exception as e:
            ctx.rollback()
            output.error(f"Migration failed: {e}")
            return 1
    elif args.dry_run:
        output.info(f"\nDry run complete. {success_count} files would be migrated.")

    return 0 if error_count == 0 else 1


if __name__ == '__main__':
    sys.exit(main())
```

---

## 4. Feature 3: Curation Levels

### 4.1 Context & Rationale

**From Master Plan (Section II):**
> **v2.9 Curation Levels** (Growth): Level 0 (Scaffold) → Level 1 (Stub) → Level 2 (Full).
>
> **Watch-out (Gemini):** Define strict validation rules per level. Level 1 must allow status: pending_curation.

**From ADR-003:**
> To de-risk the "Librarian's Wager":
> - Level 0: Scaffold (Heuristic)
> - Level 1: Stub Log (User only provides Goal)
> - Level 2: Full Ontos (Dependencies + Concepts)

**Problem:** Current Ontos requires full curation upfront:
- All documents need proper frontmatter
- depends_on expected for non-kernel types
- concepts expected for logs

This creates high friction for new users who want to adopt gradually.

### 4.2 Curation Level Definitions

| Level | Name | Description | Validation |
|-------|------|-------------|------------|
| **0** | Scaffold | Auto-generated placeholder | Minimal validation |
| **1** | Stub | User provides goal only | Relaxed validation |
| **2** | Full | Complete Ontos document | Full validation |

### 4.3 Frontmatter Field

**Field:** `curation_level` (integer: 0, 1, or 2)

**Default:** If not specified, inferred from content:
- Has depends_on + concepts → Level 2
- Has basic fields only → Level 1
- Auto-generated → Level 0

### 4.4 Validation Rules by Level

**Level 0 (Scaffold):**
```yaml
---
id: scaffolded_doc           # Required (auto-generated)
type: unknown                # Can be 'unknown'
status: scaffold             # New status value
curation_level: 0
generated_by: ontos_scaffold # Marker for auto-generation
---
```

| Field | Required | Allowed Values |
|-------|----------|----------------|
| id | Yes | any |
| type | Yes | any (including 'unknown') |
| status | No | scaffold, draft |
| depends_on | No | (ignored in validation) |
| concepts | No | (ignored in validation) |

**Level 1 (Stub):**
```yaml
---
id: my_feature_stub
type: product
status: pending_curation      # New status value
curation_level: 1
goal: "Describe the checkout flow"  # New field
---
```

| Field | Required | Allowed Values |
|-------|----------|----------------|
| id | Yes | any |
| type | Yes | any valid type (not 'unknown') |
| status | Yes | pending_curation, draft, active |
| goal | Recommended | free text |
| depends_on | No | (not required at L1) |
| concepts | No | (not required at L1) |

**Level 2 (Full):**
```yaml
---
id: checkout_flow
type: product
status: active
depends_on: [mission, v2_strategy]
concepts: [ux, checkout]
curation_level: 2
---
```

| Field | Required | Allowed Values |
|-------|----------|----------------|
| id | Yes | any |
| type | Yes | valid type |
| status | Yes | draft, active, deprecated, complete |
| depends_on | Yes* | list of IDs (*except kernel) |
| concepts | Yes* | list (*for logs) |

### 4.5 New Status Values

Add to `ontos_config_defaults.py`:

```python
VALID_STATUS = {
    'draft',
    'active',
    'deprecated',
    'archived',
    'rejected',
    'complete',
    # New in v2.9:
    'scaffold',           # Level 0 auto-generated
    'pending_curation',   # Level 1 awaiting full curation
}
```

### 4.6 CLI Commands for Curation

**New Command:** `ontos.py scaffold`

Auto-generate Level 0 stubs for untagged markdown files.

*Updated per LLM Review Board (Gemini): Defaults to --dry-run to prevent accidental mass file modification.*

```bash
# Preview what would be scaffolded (default, safe)
python3 ontos.py scaffold

# Actually apply scaffolding (explicit opt-in)
python3 ontos.py scaffold --apply

# Scaffold specific file
python3 ontos.py scaffold docs/features/new_feature.md --apply
```

**New Command:** `ontos.py stub`

Create Level 1 stub interactively:

```bash
# Interactive stub creation
python3 ontos.py stub

# With goal provided
python3 ontos.py stub --goal "Document the checkout flow" --type product

# Output to specific file
python3 ontos.py stub --output docs/product/checkout.md
```

**New Command:** `ontos.py promote` *(Added per LLM Review Board)*

Promote documents from Level 0/1 to Level 2 with interactive guidance.

*Suggested by Claude and Gemini: This was a UX gap. Users need a way to promote documents.*

```bash
# Promote a specific document (interactive)
python3 ontos.py promote docs/feature.md

# Interactive prompts:
#   "This is a 'product' document. What does it depend on?"
#   > [fuzzy search: mis...] → mission
#   "Add concepts:"
#   > ux, checkout
#   "Promoted to Level 2!"

# Promote all documents that are ready
python3 ontos.py promote --all-ready

# Dry-run promotion check
python3 ontos.py promote --check
```

**Enhanced:** `ontos.py maintain`

Add curation level reporting:

```bash
$ python3 ontos.py maintain

Curation Status:
  Level 0 (Scaffold):          3 documents
  Level 1 (Stub):              5 documents
  Level 2 (Full):             47 documents

Recommendations:
  - 3 scaffolds ready for curation (created >7 days ago)
  - 2 stubs have been modified but not promoted
```

### 4.7 .ontosignore File *(Added per LLM Review Board)*

*Suggested by Gemini: Prevent accidentally scaffolding third-party or generated docs.*

Similar to `.gitignore`, this file excludes paths from scaffolding:

```
# .ontosignore - files/directories to exclude from ontos.py scaffold

# Third-party docs
vendor/
node_modules/
.venv/

# Generated files
*.generated.md
api-docs/

# Temporary notes
scratch/
*.draft.md
```

**Implementation:**

```python
def load_ontosignore(repo_root: Path) -> list:
    """Load patterns from .ontosignore file."""
    ignore_file = repo_root / ".ontosignore"
    if not ignore_file.exists():
        return []

    patterns = []
    for line in ignore_file.read_text().split('\n'):
        line = line.strip()
        if line and not line.startswith('#'):
            patterns.append(line)
    return patterns


def should_ignore(filepath: Path, patterns: list) -> bool:
    """Check if file matches any ignore pattern."""
    import fnmatch
    path_str = str(filepath)
    for pattern in patterns:
        if fnmatch.fnmatch(path_str, f"*{pattern}*"):
            return True
    return False
```

### 4.8 Validation Modes *(Added per LLM Review Board)*

*Suggested by Codex: Prevent Level 0/1 documents from "contaminating" the dependency graph.*

```bash
# Default mode: respects curation levels (L0/L1 have relaxed validation)
python3 ontos.py map

# Strict mode: only Level 2 documents are fully valid
python3 ontos.py map --strict

# Curated mode: explicit (same as default)
python3 ontos.py map --curated
```

#### Validation Semantics *(Clarified per Codex Round 2)*

| Aspect | `--curated` (Default) | `--strict` |
|--------|----------------------|------------|
| **L2 documents** | Full validation | Full validation |
| **L1 documents** | Relaxed (type required, depends_on optional) | Warning + marked incomplete |
| **L0 documents** | Minimal (just frontmatter presence) | Warning + marked incomplete |
| **Graph inclusion** | All levels included with markers | L0/L1 excluded from traversal |
| **Dependency check** | L0/L1 deps are advisory | L0/L1 deps cause warnings |
| **Exit code** | 0 (unless hard errors) | 1 if any L0/L1 present |
| **CI recommendation** | Development/testing | Production/release gates |

**--strict Mode Behavior:**
- Level 0/1 documents are marked as "[INCOMPLETE]" in context map
- Level 0/1 documents are excluded from dependency graph traversal
- Warnings shown for documents not at Level 2
- Exit code 1 if any documents are below Level 2
- Staleness checks only apply to L2 documents

**Context Map Display (Updated per LLM Review Board):**

*Claude and Codex both suggested showing curation level in the context map.*

```markdown
## 2. Document Hierarchy

### kernel (1 document)
- **mission** [L2] (kernel/mission.md) ~400 tokens

### strategy (3 documents)
- **v2_strategy** [L2] (strategy/v2_strategy.md) ~2100 tokens
- **master_plan_v4** [L2] (strategy/master_plan.md) ~3200 tokens
- **new_roadmap** [L1] (strategy/roadmap.md) ~100 tokens  ⚠️ pending_curation

### atom (5 documents)
- **auth_flow** [L2] (technical/auth_flow.md) ~800 tokens
- **scaffolded_doc** [L0] (technical/new.md) ~50 tokens  ⚠️ scaffold
```

### 4.9 Implementation: Curation Module

**New File:** `.ontos/scripts/ontos/core/curation.py`

```python
"""Curation level validation and scaffolding.

Curation Levels:
    0 - Scaffold: Auto-generated, minimal validation
    1 - Stub: User provides goal, relaxed validation
    2 - Full: Complete Ontos document, full validation
"""

from dataclasses import dataclass
from enum import IntEnum
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re


class CurationLevel(IntEnum):
    """Document curation levels."""
    SCAFFOLD = 0
    STUB = 1
    FULL = 2


@dataclass
class CurationInfo:
    """Curation status of a document."""
    level: CurationLevel
    explicit: bool  # True if curation_level field present
    issues: List[str]
    promotable: bool  # Can be promoted to next level
    promotion_blockers: List[str]


# Type heuristics for scaffolding
# Updated per LLM Review Board (Claude): Use word boundaries to prevent
# "login" matching "log", "implementation" matching "plan", etc.
TYPE_HEURISTICS = {
    'kernel': [
        r'\bmission\b', r'\bprinciple\b', r'\bvalues\b', r'\bphilosophy\b',
    ],
    'strategy': [
        r'\bstrategy\b', r'\broadmap\b', r'\bplan\b', r'\bgoal\b', r'\bobjective\b',
    ],
    'product': [
        r'\bfeature\b', r'\brequirement\b', r'\bspec\b', r'\buser.*story\b', r'\bflow\b',
    ],
    'atom': [
        r'\bapi\b', r'\bimplementation\b', r'\btechnical\b', r'\barchitecture\b',
        r'\bmodule\b', r'\bcomponent\b', r'\bservice\b',
    ],
    'log': [
        r'\bsession\b', r'\blog\b', r'\bdecision\b', r'\d{4}-\d{2}-\d{2}',
    ],
}


def infer_type_from_path(filepath: Path) -> str:
    """Infer document type from file path."""
    path_str = str(filepath).lower()

    # Check directory names
    if '/kernel/' in path_str or '/mission/' in path_str:
        return 'kernel'
    if '/strategy/' in path_str or '/roadmap/' in path_str:
        return 'strategy'
    if '/product/' in path_str or '/features/' in path_str:
        return 'product'
    if '/logs/' in path_str or '/sessions/' in path_str:
        return 'log'
    if '/atom/' in path_str or '/technical/' in path_str:
        return 'atom'

    return 'unknown'


def infer_type_from_content(content: str) -> str:
    """Infer document type from content keywords."""
    content_lower = content.lower()

    scores = {t: 0 for t in TYPE_HEURISTICS}

    for doc_type, patterns in TYPE_HEURISTICS.items():
        for pattern in patterns:
            matches = len(re.findall(pattern, content_lower))
            scores[doc_type] += matches

    # Return type with highest score, or 'unknown'
    best_type = max(scores, key=scores.get)
    if scores[best_type] > 0:
        return best_type

    return 'unknown'


def generate_id_from_path(filepath: Path) -> str:
    """Generate document ID from file path."""
    # Remove extension
    name = filepath.stem

    # Convert to snake_case
    name = re.sub(r'[-\s]+', '_', name)
    name = re.sub(r'[^a-zA-Z0-9_]', '', name)
    name = name.lower()

    # Ensure valid identifier
    if name[0].isdigit():
        name = 'doc_' + name

    return name


def detect_curation_level(frontmatter: dict) -> CurationLevel:
    """Detect curation level from frontmatter."""
    # Explicit level takes precedence
    if 'curation_level' in frontmatter:
        level = frontmatter['curation_level']
        if isinstance(level, int) and 0 <= level <= 2:
            return CurationLevel(level)

    # Infer from status
    status = frontmatter.get('status', '')
    if status == 'scaffold':
        return CurationLevel.SCAFFOLD
    if status == 'pending_curation':
        return CurationLevel.STUB

    # Infer from field presence
    has_depends = bool(frontmatter.get('depends_on'))
    has_concepts = bool(frontmatter.get('concepts'))
    doc_type = frontmatter.get('type', '')

    if doc_type == 'unknown':
        return CurationLevel.SCAFFOLD

    # Logs need concepts for Level 2
    if doc_type == 'log':
        if has_concepts:
            return CurationLevel.FULL
        return CurationLevel.STUB

    # Non-kernel types need depends_on for Level 2
    if doc_type != 'kernel':
        if has_depends:
            return CurationLevel.FULL
        return CurationLevel.STUB

    # Kernel types are full if they have basic fields
    return CurationLevel.FULL


def validate_at_level(
    frontmatter: dict,
    level: CurationLevel
) -> Tuple[bool, List[str]]:
    """Validate frontmatter at specified curation level.

    Returns:
        (is_valid, list_of_issues)
    """
    issues = []

    # Level 0: Minimal validation
    if level == CurationLevel.SCAFFOLD:
        if 'id' not in frontmatter:
            issues.append("Missing required field: id")
        if 'type' not in frontmatter:
            issues.append("Missing required field: type")
        return (len(issues) == 0, issues)

    # Level 1: Relaxed validation
    if level == CurationLevel.STUB:
        if 'id' not in frontmatter:
            issues.append("Missing required field: id")
        if 'type' not in frontmatter:
            issues.append("Missing required field: type")
        elif frontmatter['type'] == 'unknown':
            issues.append("Type must be specified (not 'unknown') at Level 1")
        if 'status' not in frontmatter:
            issues.append("Missing required field: status")
        return (len(issues) == 0, issues)

    # Level 2: Full validation
    if level == CurationLevel.FULL:
        if 'id' not in frontmatter:
            issues.append("Missing required field: id")
        if 'type' not in frontmatter:
            issues.append("Missing required field: type")
        if 'status' not in frontmatter:
            issues.append("Missing required field: status")

        doc_type = frontmatter.get('type', '')
        status = frontmatter.get('status', '')

        # Status validation
        if status in ('scaffold', 'pending_curation'):
            issues.append(f"Status '{status}' not allowed at Level 2")

        # depends_on required for non-kernel
        if doc_type not in ('kernel', 'log') and not frontmatter.get('depends_on'):
            issues.append(f"Type '{doc_type}' requires depends_on at Level 2")

        # concepts required for logs
        if doc_type == 'log' and not frontmatter.get('concepts'):
            issues.append("Type 'log' requires concepts at Level 2")

        return (len(issues) == 0, issues)

    return (True, [])


def check_promotion_readiness(
    frontmatter: dict,
    current_level: CurationLevel
) -> Tuple[bool, List[str]]:
    """Check if document is ready to be promoted to next level.

    Returns:
        (is_promotable, list_of_blockers)
    """
    if current_level == CurationLevel.FULL:
        return (False, ["Already at maximum curation level"])

    next_level = CurationLevel(current_level + 1)
    is_valid, issues = validate_at_level(frontmatter, next_level)

    if is_valid:
        return (True, [])
    else:
        return (False, issues)


def create_scaffold(
    filepath: Path,
    content: Optional[str] = None
) -> dict:
    """Create Level 0 scaffold frontmatter for a file."""
    if content is None:
        content = filepath.read_text() if filepath.exists() else ""

    # Generate ID from path
    doc_id = generate_id_from_path(filepath)

    # Infer type
    doc_type = infer_type_from_path(filepath)
    if doc_type == 'unknown':
        doc_type = infer_type_from_content(content)

    return {
        'id': doc_id,
        'type': doc_type,
        'status': 'scaffold',
        'curation_level': 0,
        'ontos_schema': '2.2',
        'generated_by': 'ontos_scaffold',
    }


def create_stub(
    doc_id: str,
    doc_type: str,
    goal: str,
    depends_on: Optional[List[str]] = None
) -> dict:
    """Create Level 1 stub frontmatter."""
    result = {
        'id': doc_id,
        'type': doc_type,
        'status': 'pending_curation',
        'curation_level': 1,
        'ontos_schema': '2.2',
        'goal': goal,
    }

    if depends_on:
        result['depends_on'] = depends_on

    return result


def promote_to_full(
    frontmatter: dict,
    depends_on: Optional[List[str]] = None,
    concepts: Optional[List[str]] = None
) -> Tuple[dict, Optional[str]]:
    """Promote document to Level 2 (Full).

    Returns:
        (updated_frontmatter, optional_summary_from_goal)

    Updated per LLM Review Board (Claude): Don't discard the goal field.
    Instead, return it so it can be used to seed the document summary.
    """
    result = frontmatter.copy()

    result['curation_level'] = 2
    result['ontos_schema'] = '2.2'

    # Update status
    if result.get('status') in ('scaffold', 'pending_curation'):
        result['status'] = 'draft'

    # Extract goal before removing (Claude's feedback: "goal is write-only")
    # The caller can use this to seed a document summary
    goal_summary = result.pop('goal', None)

    # Remove scaffold markers
    if 'generated_by' in result:
        del result['generated_by']

    # Add required fields
    if depends_on:
        result['depends_on'] = depends_on
    if concepts:
        result['concepts'] = concepts

    return (result, goal_summary)
```

### 4.10 Scaffold Command Implementation

**New Script:** `.ontos/scripts/ontos_scaffold.py`

```python
#!/usr/bin/env python3
"""Generate Level 0 scaffolds for untagged markdown files.

Usage:
    python3 ontos.py scaffold              # Preview scaffolds (dry-run default)
    python3 ontos.py scaffold --apply      # Actually apply scaffolds
    python3 ontos.py scaffold docs/new.md  # Scaffold specific file (dry-run)
    python3 ontos.py scaffold docs/new.md --apply  # Apply to specific file
"""

import argparse
import sys
from pathlib import Path

SCRIPTS_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPTS_DIR))

from ontos.core.curation import create_scaffold, infer_type_from_path
from ontos.core.frontmatter import parse_frontmatter
from ontos.core.schema import serialize_frontmatter  # stdlib-only serialization
from ontos.core.context import SessionContext
from ontos.ui.output import OutputHandler


def find_untagged_files(docs_dir: Path) -> list:
    """Find markdown files without frontmatter."""
    untagged = []

    for md_file in docs_dir.rglob("*.md"):
        # Skip internal and archive directories
        if '.ontos' in str(md_file) or 'archive' in str(md_file):
            continue

        content = md_file.read_text()

        # Check for frontmatter
        if not content.startswith('---'):
            untagged.append(md_file)
            continue

        # Check for valid frontmatter
        try:
            fm = parse_frontmatter(md_file)
            if not fm or 'id' not in fm:
                untagged.append(md_file)
        except Exception:
            untagged.append(md_file)

    return untagged


def add_frontmatter_to_file(
    filepath: Path,
    frontmatter: dict,
    ctx: SessionContext
) -> None:
    """Add frontmatter to a file."""
    content = filepath.read_text()

    # Remove existing frontmatter if present
    if content.startswith('---'):
        lines = content.split('\n')
        end_idx = None
        for i, line in enumerate(lines[1:], 1):
            if line == '---':
                end_idx = i
                break
        if end_idx:
            content = '\n'.join(lines[end_idx+1:])

    # Build new content using stdlib-only serialization
    fm_yaml = serialize_frontmatter(frontmatter)
    new_content = f"---\n{fm_yaml}\n---\n{content}"

    ctx.buffer_write(filepath, new_content)


def main() -> int:
    parser = argparse.ArgumentParser(description="Generate Level 0 scaffolds")
    parser.add_argument('files', nargs='*', help="Specific files to scaffold")
    # Default to dry-run for safety (per Gemini Round 1, Claude Round 2)
    parser.add_argument('--apply', action='store_true',
                        help="Apply changes (default: dry-run preview only)")
    parser.add_argument('--quiet', '-q', action='store_true', help="Quiet output")
    args = parser.parse_args()

    # Dry-run is the default; --apply is required to make changes
    dry_run = not args.apply

    output = OutputHandler(quiet=args.quiet)
    ctx = SessionContext.from_repo(Path.cwd())

    # Find files to scaffold
    from ontos_config import DOCS_DIR
    docs_dir = Path(DOCS_DIR)

    if args.files:
        files = [Path(f) for f in args.files if Path(f).exists()]
    else:
        files = find_untagged_files(docs_dir)

    if not files:
        output.info("No untagged files found.")
        return 0

    output.info(f"Found {len(files)} files to scaffold")

    scaffolded = 0
    for filepath in files:
        # Generate scaffold
        scaffold = create_scaffold(filepath)

        if dry_run:
            output.info(f"Would scaffold: {filepath}")
            output.detail(f"  id: {scaffold['id']}")
            output.detail(f"  type: {scaffold['type']}")
        else:
            add_frontmatter_to_file(filepath, scaffold, ctx)
            output.success(f"Scaffolded: {filepath}")
            scaffolded += 1

    if not dry_run and scaffolded > 0:
        try:
            modified = ctx.commit()
            output.success(f"\nScaffolded {len(modified)} files")
        except Exception as e:
            ctx.rollback()
            output.error(f"Failed: {e}")
            return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
```

### 4.11 Promote Command Implementation *(Added per Claude Round 2)*

**New Script:** `.ontos/scripts/ontos_promote.py`

```python
#!/usr/bin/env python3
"""Promote documents from Level 0/1 to Level 2 with interactive guidance.

Usage:
    python3 ontos.py promote docs/feature.md   # Promote specific file
    python3 ontos.py promote --all-ready       # Promote all ready documents
    python3 ontos.py promote --check           # Show promotion status
"""

import argparse
import sys
from pathlib import Path

SCRIPTS_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPTS_DIR))

from ontos.core.context import SessionContext
from ontos.core.output import OutputHandler
from ontos.core.frontmatter import parse_frontmatter
from ontos.core.curation import (
    get_curation_level,
    promote_to_full,
    CURATION_LEVELS,
)
from ontos.core.schema import serialize_frontmatter


def fuzzy_find_ids(query: str, existing_ids: list[str]) -> list[str]:
    """Simple fuzzy matching for document IDs."""
    query_lower = query.lower()
    return [id_ for id_ in existing_ids if query_lower in id_.lower()]


def interactive_promote(filepath: Path, frontmatter: dict, existing_ids: list[str],
                        existing_concepts: list[str], output: OutputHandler) -> dict:
    """Interactively guide user through promotion to Level 2."""
    doc_type = frontmatter.get('type', 'atom')
    output.info(f"\nPromoting '{frontmatter.get('id', filepath.stem)}' (type: {doc_type})")

    # Step 1: depends_on
    if 'depends_on' not in frontmatter or not frontmatter['depends_on']:
        output.info("\nStep 1: What does this document depend on?")
        output.detail(f"  (Available: {', '.join(existing_ids[:5])}...)")
        deps_input = input("  depends_on (comma-separated, or empty): ").strip()
        if deps_input:
            deps = [d.strip() for d in deps_input.split(',')]
            frontmatter['depends_on'] = deps

    # Step 2: concepts
    if 'concepts' not in frontmatter or not frontmatter['concepts']:
        output.info("\nStep 2: Add concepts/tags for this document")
        output.detail(f"  (Existing: {', '.join(existing_concepts[:10])}...)")
        concepts_input = input("  concepts (comma-separated): ").strip()
        if concepts_input:
            concepts = [c.strip() for c in concepts_input.split(',')]
            frontmatter['concepts'] = concepts

    # Step 3: Goal seeding (per Gemini Round 2)
    goal = frontmatter.pop('goal', None)  # Remove goal field on promotion

    return frontmatter, goal


def seed_summary_from_goal(filepath: Path, goal: str, ctx: SessionContext,
                           output: OutputHandler) -> bool:
    """Offer to seed document summary from Level 1 goal field (per Gemini Round 2)."""
    content = ctx.read_file(filepath)

    # Check if body is minimal (< 5 non-empty lines after frontmatter)
    lines = content.split('\n')
    in_frontmatter = False
    body_lines = []
    for line in lines:
        if line.strip() == '---':
            in_frontmatter = not in_frontmatter
            continue
        if not in_frontmatter:
            if line.strip():
                body_lines.append(line)

    if len(body_lines) < 5 and goal:
        output.info(f"\n  Document body is minimal. Goal was: \"{goal}\"")
        seed = input("  Add goal as Summary section? [Y/n]: ").strip().lower()
        if seed != 'n':
            return goal  # Return goal to be added as summary
    return None


def main() -> int:
    parser = argparse.ArgumentParser(description="Promote documents to Level 2")
    parser.add_argument('files', nargs='*', help="Specific files to promote")
    parser.add_argument('--all-ready', action='store_true',
                        help="Promote all documents ready for promotion")
    parser.add_argument('--check', action='store_true', help="Show promotion status")
    parser.add_argument('--quiet', '-q', action='store_true', help="Quiet output")
    args = parser.parse_args()

    output = OutputHandler(quiet=args.quiet)
    ctx = SessionContext.from_repo(Path.cwd())

    # Gather existing IDs and concepts for fuzzy matching
    from ontos_config import DOCS_DIR
    docs_dir = Path(DOCS_DIR)
    existing_ids = []
    existing_concepts = set()

    for md_file in docs_dir.rglob('*.md'):
        fm, _ = parse_frontmatter(ctx.read_file(md_file))
        if fm and 'id' in fm:
            existing_ids.append(fm['id'])
        if fm and 'concepts' in fm:
            existing_concepts.update(fm['concepts'])

    existing_concepts = sorted(existing_concepts)

    # Find files to promote
    if args.files:
        files = [Path(f) for f in args.files]
    elif args.all_ready:
        # Find Level 0/1 documents that have been modified recently
        files = []
        for md_file in docs_dir.rglob('*.md'):
            fm, _ = parse_frontmatter(ctx.read_file(md_file))
            if fm:
                level = get_curation_level(fm)
                if level < 2:  # Level 0 or 1
                    files.append(md_file)
    else:
        output.error("Specify files or use --all-ready")
        return 1

    if args.check:
        output.info("Promotion status:")
        for filepath in files:
            fm, _ = parse_frontmatter(ctx.read_file(filepath))
            level = get_curation_level(fm) if fm else 0
            output.detail(f"  {filepath}: Level {level}")
        return 0

    # Promote each file
    promoted = 0
    for filepath in files:
        content = ctx.read_file(filepath)
        fm, body = parse_frontmatter(content)

        if not fm:
            output.warning(f"Skipping {filepath}: no frontmatter")
            continue

        level = get_curation_level(fm)
        if level >= 2:
            output.info(f"Skipping {filepath}: already Level 2")
            continue

        # Interactive promotion
        new_fm, goal = interactive_promote(filepath, fm, existing_ids,
                                           existing_concepts, output)

        # Check if we should seed summary from goal
        summary_to_add = seed_summary_from_goal(filepath, goal, ctx, output)
        if summary_to_add:
            # Add summary section to body
            title = new_fm.get('id', filepath.stem).replace('_', ' ').title()
            summary_section = f"# {title}\n\n## Summary\n\n{summary_to_add}\n\n"
            body = summary_section + body.lstrip()

        # Update curation_level
        new_fm['curation_level'] = 2

        # Rebuild document
        fm_yaml = serialize_frontmatter(new_fm)
        new_content = f"---\n{fm_yaml}\n---\n{body}"

        ctx.buffer_write(filepath, new_content)
        output.success(f"Promoted: {filepath} → Level 2")
        promoted += 1

    if promoted > 0:
        try:
            modified = ctx.commit()
            output.success(f"\nPromoted {len(modified)} files to Level 2")
        except Exception as e:
            ctx.rollback()
            output.error(f"Failed: {e}")
            return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
```

#### 4.12.1 Actual API (PR #33)

> **✅ IMPLEMENTED in PR #33** (merged 2025-12-22 as v2.9.1)
>
> The implementation closely follows the plan. **PR #34 and beyond should use this actual API:**

**Classes/Enums:**
```python
class CurationLevel(IntEnum):
    SCAFFOLD = 0  # Auto-generated placeholder
    STUB = 1      # User provides goal only
    FULL = 2      # Complete Ontos document

@dataclass
class CurationInfo:
    level: CurationLevel
    explicit: bool           # True if curation_level field present
    issues: List[str]        # Validation issues at current level
    promotable: bool         # Can be promoted to next level
    promotion_blockers: List[str]  # What's needed for promotion
```

**Functions:**
```python
# Type inference
def infer_type_from_path(filepath: Path) -> str
def infer_type_from_content(content: str) -> str
def generate_id_from_path(filepath: Path) -> str

# Level detection and validation
def detect_curation_level(frontmatter: Dict[str, Any]) -> CurationLevel
def validate_at_level(frontmatter: Dict[str, Any], level: CurationLevel) -> Tuple[bool, List[str]]
def check_promotion_readiness(frontmatter: Dict[str, Any], current_level: CurationLevel) -> Tuple[bool, List[str]]
def get_curation_info(frontmatter: Dict[str, Any]) -> CurationInfo

# Scaffold/stub creation
def create_scaffold(filepath: Path, content: Optional[str] = None) -> Dict[str, Any]
def create_stub(doc_id: str, doc_type: str, goal: str, depends_on: Optional[List[str]] = None) -> Dict[str, Any]
def promote_to_full(frontmatter: Dict[str, Any], depends_on: Optional[List[str]] = None, concepts: Optional[List[str]] = None) -> Tuple[Dict[str, Any], Optional[str]]

# Ignore patterns
def load_ontosignore(repo_root: Path) -> List[str]
def should_ignore(filepath: Path, patterns: List[str]) -> bool

# Display
def level_marker(level: CurationLevel) -> str  # Returns "[L0]", "[L1]", or "[L2]"
```

**Constants:**
```python
TYPE_HEURISTICS: Dict[str, List[str]]  # Regex patterns per type (with word boundaries)
```

**Key Alignment with Plan:**

| Aspect | Plan | Actual |
|--------|------|--------|
| Level enum | `CurationLevel(IntEnum)` | ✅ Matches |
| `create_scaffold()` | Returns frontmatter dict | ✅ Matches |
| `create_stub()` | Takes id, type, goal | ✅ Matches |
| `promote_to_full()` | Returns (fm, summary_seed) | ✅ Matches |
| Type heuristics | Word boundaries | ✅ Matches (per Claude feedback) |
| `.ontosignore` | Gitignore-style patterns | ✅ Matches |

**CLI Commands Added:**
- `python3 ontos.py scaffold` — Generate Level 0 scaffolds (`--apply` to execute)
- `python3 ontos.py stub` — Create Level 1 stubs
- `python3 ontos.py promote` — Interactive L0/L1 → L2 promotion
- `curate` alias → `scaffold`

**Context Map Integration:**
- `[L0]`, `[L1]`, `[L2]` markers in document listings
- `--strict` mode exits with code 1 if L0/L1 documents present

---

## 5. Feature 4: Deprecation Warnings

### 5.1 Context & Rationale

**From v2.8 Implementation Plan (Section 2.6):**
> v2.8: Silent operation (no warnings)
> v2.9: DeprecationWarning on import
> v3.0: Module removed

v2.9 activates deprecation warnings for:
1. Direct imports from `ontos_lib`
2. Direct script execution (vs `ontos.py` CLI)

### 5.2 Implementation: ontos_lib.py Warnings

*Updated per LLM Review Board (Codex): Use FutureWarning instead of DeprecationWarning because DeprecationWarning is silenced by default.*

Update `.ontos/scripts/ontos_lib.py`:

```python
"""
DEPRECATED: Import from ontos.core instead.
This module will be removed in v3.0.

v2.8: Silent operation
v2.9: FutureWarning on import (CURRENT) - visible by default
v3.0: Module removed
"""

import warnings

# Emit warning on import
# Using FutureWarning instead of DeprecationWarning because
# DeprecationWarning is silenced by default (Codex's insight)
warnings.warn(
    "Importing from 'ontos_lib' is deprecated. "
    "Import from 'ontos.core' instead. "
    "This module will be removed in v3.0. "
    "See: docs/reference/Ontos_Manual.md#migration-guide",
    FutureWarning,  # Visible by default, unlike DeprecationWarning
    stacklevel=2
)

# Re-exports remain unchanged
from ontos.core.frontmatter import parse_frontmatter, normalize_depends_on
from ontos.core.staleness import (
    ModifiedSource, normalize_describes, parse_describes_verified,
    validate_describes_field, detect_describes_cycles, check_staleness,
    get_file_modification_date, clear_git_cache
)
# ... rest of re-exports
```

### 5.3 Implementation: Script Deprecation Warnings

Each script should warn when run directly:

```python
# At the bottom of each script (e.g., ontos_end_session.py)

if __name__ == '__main__':
    import warnings
    import os

    # Check if running via ontos.py dispatcher
    if not os.environ.get('ONTOS_CLI_DISPATCH'):
        # Check for suppression env var (for CI/CD pipelines)
        if not os.environ.get('ONTOS_NO_DEPRECATION_WARNINGS'):
            warnings.warn(
                f"Direct execution of {__file__} is deprecated. "
                "Use 'python3 ontos.py log' instead. "
                "Direct script execution will be removed in v3.0.",
                FutureWarning,  # Visible by default
                stacklevel=1
            )

    sys.exit(main())
```

Update `ontos.py` to set environment variable:

```python
def main():
    # ... existing code ...

    # Set environment variable to suppress deprecation warning in dispatched scripts
    os.environ['ONTOS_CLI_DISPATCH'] = '1'

    # Import and run the module
    # ... existing code ...
```

### 5.4 CLI Deprecation Notice *(Added per Codex Round 2)*

*FutureWarning is better than DeprecationWarning but can still be filtered. Add explicit CLI notice for guaranteed visibility.*

```python
def emit_deprecation_notice(message: str) -> None:
    """Always-visible CLI notice for deprecated usage.

    This bypasses Python's warning system to ensure users see deprecation notices.
    """
    import sys
    print(f"[DEPRECATION] {message}", file=sys.stderr)
```

**Usage in deprecated scripts:**
```python
if __name__ == '__main__':
    import os
    if not os.environ.get('ONTOS_CLI_DISPATCH'):
        if not os.environ.get('ONTOS_NO_DEPRECATION_WARNINGS'):
            emit_deprecation_notice(
                f"Direct execution of {__file__} is deprecated. "
                "Use 'python3 ontos.py <command>' instead."
            )
    sys.exit(main())
```

### 5.5 Warning Suppression for CI/CD

*Added per LLM Review Board (Codex): CI systems need a way to suppress warnings.*

```bash
# Suppress deprecation warnings in CI pipelines
ONTOS_NO_DEPRECATION_WARNINGS=1 python3 ontos.py map --strict
```

**GitHub Actions example:**
```yaml
jobs:
  validate:
    runs-on: ubuntu-latest
    env:
      ONTOS_NO_DEPRECATION_WARNINGS: "1"
    steps:
      - uses: actions/checkout@v4
      - name: Validate Ontos
        run: python3 ontos.py map --strict
```

### 5.6 Test Updates for Warnings

Add warning filters to `tests/conftest.py`:

```python
import warnings

# Configure pytest to show deprecation warnings from ontos
def pytest_configure(config):
    # Show deprecation warnings from our code
    warnings.filterwarnings(
        "always",
        category=FutureWarning,
        module=r"ontos.*"
    )

    # But allow tests to use old imports without noise
    # (tests themselves may test the shim)
    warnings.filterwarnings(
        "ignore",
        message="Importing from 'ontos_lib' is deprecated",
        category=FutureWarning,
    )
```

### 5.7 Deprecation Suppression Policy *(Added v1.5.0 per Codex v2.9.4 Review)*

**Important Clarification:** The `ONTOS_NO_DEPRECATION_WARNINGS=1` environment variable suppresses CLI deprecation notices, but **intentionally does NOT suppress** the `FutureWarning` from `ontos_lib` imports.

**Rationale:** CLI notices are user-facing (annoying in scripts). Import warnings are developer-facing (essential for migration planning). Developers need to see import warnings to update their code before v3.0.

| Warning Type | Source | Suppressible | Why |
|--------------|--------|--------------|-----|
| CLI notice | Direct script execution | ✅ `ONTOS_NO_DEPRECATION_WARNINGS=1` | UX in CI/CD |
| `FutureWarning` | `import ontos_lib` | ❌ Intentionally unsuppressible | Developer must migrate |

### 5.8 Internal-Only Scripts *(Added v1.5.0 per Codex v2.9.4 Review)*

The following scripts are **internal-only** (called by other scripts or hooks, not directly by users) and therefore do **not** need deprecation notices:

| Script | Purpose | Called By |
|--------|---------|-----------|
| `ontos_install_hooks.py` | Install git hooks | `ontos_init.py` |
| `ontos_migrate_frontmatter.py` | v1→v2 migration | Migration tools |
| `ontos_migrate_v2.py` | v1→v2 migration | Migration tools |
| `ontos_pre_commit_check.py` | Pre-commit hook | Git hook |
| `ontos_pre_push_check.py` | Pre-push hook | Git hook |
| `ontos_remove_frontmatter.py` | Cleanup utility | Admin only |
| `ontos_summarize.py` | LLM summarization | Internal tooling |

**User-facing scripts** that DO have deprecation notices:
- `ontos_archive_session.py` → `ontos.py archive`
- `ontos_end_session.py` → `ontos.py log`
- `ontos_generate_context_map.py` → `ontos.py map`
- `ontos_maintain.py` → `ontos.py maintain`
- `ontos_query.py` → `ontos.py query`
- `ontos_start_session.py` → `ontos.py start`
- `ontos_update.py` → `ontos.py update`
- `ontos_validate.py` → `ontos.py validate`

---

## 6. Implementation Phases

### Phase Overview

*Note: Original PR numbering. Actual PRs diverged during implementation—see Section 12 for actual PR numbers.*

| Planned | Feature | Actual PR | Status |
|---------|---------|-----------|--------|
| #31 | Schema Versioning | **#31** | ✅ MERGED |
| #32 | Curation Levels | **#33** | ✅ MERGED |
| #33 | Deprecation Warnings | **#34** | ✅ MERGED |
| #34 | install.py Bootstrap | **#35** | ✅ MERGED |
| #35 | Documentation & Release | **#36** | 🔄 NEXT |

---

### PR #31: Schema Versioning

**Goal:** Add schema version field and migration tooling.

| Task | Description | Files |
|------|-------------|-------|
| 31.1 | Create `ontos/core/schema.py` module | New file |
| 31.2 | Add `ontos_schema` to frontmatter parsing | `frontmatter.py` |
| 31.3 | Add schema detection to validation | `ontos_generate_context_map.py` |
| 31.4 | Create `ontos_migrate_schema.py` script | New file |
| 31.5 | Add `migrate` to CLI dispatcher | `ontos.py` |
| 31.6 | Add schema version to config defaults | `ontos_config_defaults.py` |
| 31.7 | Write tests for schema module | `tests/test_schema.py` |

**Exit Criteria:**
- `ontos_schema` field recognized in frontmatter
- `python3 ontos.py migrate --check` works
- Migration applies `ontos_schema: "2.2"` to documents
- All existing tests pass
- New tests cover schema detection and migration

---

### PR #32: Curation Levels

**Goal:** Implement tiered validation with scaffold/stub/full levels.

| Task | Description | Files |
|------|-------------|-------|
| 32.1 | Create `ontos/core/curation.py` module | New file |
| 32.2 | Add `curation_level` to frontmatter parsing | `frontmatter.py` |
| 32.3 | Add new status values | `ontos_config_defaults.py` |
| 32.4 | Create `ontos_scaffold.py` script | New file |
| 32.5 | Create `ontos_stub.py` script | New file |
| 32.6 | Add commands to CLI dispatcher | `ontos.py` |
| 32.7 | Update validation to respect levels | `ontos_generate_context_map.py` |
| 32.8 | Add curation status to maintain output | `ontos_maintain.py` |
| 32.9 | Write tests for curation module | `tests/test_curation.py` |

**Exit Criteria:**
- `python3 ontos.py scaffold` generates Level 0 documents
- `python3 ontos.py stub --goal "..." --type product` works
- Validation relaxed at Level 0/1
- Maintain shows curation status breakdown
- All tests pass

---

### PR #33: Deprecation Warnings

**Goal:** Activate deprecation warnings for v3.0 preparation.

| Task | Description | Files |
|------|-------------|-------|
| 33.1 | Add warning to ontos_lib.py | `ontos_lib.py` |
| 33.2 | Add ONTOS_CLI_DISPATCH env var | `ontos.py` |
| 33.3 | Add warnings to direct script execution | All scripts |
| 33.4 | Configure pytest warning filters | `conftest.py` |
| 33.5 | Update migration guide with deprecation info | `Ontos_Manual.md` |
| 33.6 | Write tests for warning behavior | `tests/test_deprecation.py` |

**Exit Criteria:**
- `from ontos_lib import X` emits DeprecationWarning
- Direct script execution emits DeprecationWarning
- `python3 ontos.py <cmd>` does NOT emit warnings
- Tests pass without warning noise

---

### PR #34: install.py Bootstrap

**Goal:** Create single-file installer with checksum verification.

| Task | Description | Files |
|------|-------------|-------|
| 34.1 | Create `install.py` in project root | New file |
| 34.2 | Create `ontos_create_bundle.py` | New file |
| 34.3 | Update release workflow for bundle | `.github/workflows/release.yml` |
| 34.4 | Test installation flow end-to-end | Manual testing |
| 34.5 | Document installation in README | `README.md` |
| 34.6 | Write integration tests | `tests/test_install.py` |

**Exit Criteria:**
- `curl ... && python3 install.py` works
- Checksum verification blocks tampered bundles
- `--upgrade` preserves user config
- `--check` verifies installation
- Tests cover key scenarios

---

### PR #35: Documentation & Release

**Goal:** Update all documentation and prepare v2.9.0 release.

| Task | Description | Files |
|------|-------------|-------|
| 35.1 | Update Manual with v2.9 features | `Ontos_Manual.md` |
| 35.2 | Update Agent Instructions | `Ontos_Agent_Instructions.md` |
| 35.3 | Update README with new install method | `README.md` |
| 35.4 | Write CHANGELOG entry | `Ontos_CHANGELOG.md` |
| 35.5 | Version bump to 2.9.0 | `ontos_config_defaults.py` |
| 35.6 | Final test suite run | All tests |
| 35.7 | Update this implementation plan status | This file |

**Exit Criteria:**
- All documentation reflects v2.9 features
- CHANGELOG complete
- All tests pass
- Ready for release

---

## 7. Open Questions — Resolved

*All questions were addressed by the LLM Review Board.*

### Q1: Schema Version Numbering — RESOLVED

**Question:** Should schema versions match Ontos versions (2.9, 3.0) or be independent (1.0, 2.0)?

**Options:**
- **A:** Match Ontos versions (2.9, 3.0) — simpler mental model
- **B:** Independent numbering (1.0, 2.0, 3.0) — allows schema to evolve independently

**Decision:** **Option B** — Independent versioning (2.0, 2.1, 2.2, 3.0)

*Gemini's insight: "A schema only needs to change when the *data structure* changes, not when the *code* changes. Tightly coupling them will lead to unnecessary schema bumps for most releases."*

*Codex agreed: "Explicit schema contracts required."*

---

### Q2: Default Curation Level for Existing Documents — RESOLVED

**Question:** What curation level should existing documents (without `curation_level` field) be treated as?

**Options:**
- **A:** Level 2 (Full) — maintains current validation strictness
- **B:** Infer from fields — flexible but inconsistent
- **C:** Level 1 (Stub) — permissive, avoids breaking existing projects

**Decision:** **Option B** — Infer from fields

*All reviewers agreed inference is acceptable for backwards compatibility.*

---

### Q3: install.py Bundle Format — RESOLVED

**Question:** How should the bundle be distributed?

**Options:**
- **A:** tar.gz archive — standard, works everywhere
- **B:** zip archive — easier for Windows users
- **C:** Both formats — maximum compatibility

**Decision:** **Option A** — tar.gz

*Python's tarfile is stdlib. Codex noted Windows compatibility should be documented.*

---

### Q4: Scaffold Type Inference — RESOLVED

**Question:** How aggressive should type inference be for Level 0 scaffolds?

**Options:**
- **A:** Conservative — default to 'unknown' unless confident
- **B:** Aggressive — always guess, user can correct
- **C:** User choice — `--guess` flag for aggressive mode

**Decision:** **Option A** — Conservative

*All reviewers agreed. Claude added: "Use word boundaries to prevent misclassification."*

---

### Q5: Deprecation Warning Suppression — RESOLVED

**Question:** Should there be a way to suppress deprecation warnings?

**Options:**
- **A:** No suppression — force migration
- **B:** Environment variable — `ONTOS_NO_DEPRECATION_WARNINGS=1`
- **C:** Config option — `SUPPRESS_DEPRECATION_WARNINGS = True`

**Decision:** **Option B** — Environment variable `ONTOS_NO_DEPRECATION_WARNINGS=1`

*Codex added: Use FutureWarning instead of DeprecationWarning because DeprecationWarning is silenced by default.*

---

## 8. Success Criteria

### Core Requirements

1. **install.py** downloads and installs Ontos with one command
2. **SHA256 verification** blocks tampered bundles
3. **Schema versioning** detects document versions automatically
4. **Migration tool** upgrades documents to current schema
5. **Curation levels** allow tiered validation (0/1/2)
6. **Scaffold command** generates Level 0 stubs
7. **Deprecation warnings** prepare users for v3.0

### Testing Requirements

8. All 285+ existing tests pass
9. New tests for schema module (10+ tests)
10. New tests for curation module (15+ tests)
11. New tests for install.py (5+ tests)
12. Integration test for full install flow

### Documentation Requirements

13. Manual updated with all v2.9 features
14. Agent Instructions updated
15. README shows new install method
16. Migration guide for v2.8 → v2.9

### Quality Requirements

17. Strict validation passes
18. No new warnings (except intentional deprecations)
19. Bundle size < 500KB
20. Install time < 30 seconds on typical connection

---

## 9. Risk Analysis

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| install.py security vulnerability | Low | Critical | SHA256 verification, code review |
| Schema migration breaks documents | Medium | High | Extensive testing, dry-run mode |
| Curation levels confuse users | Medium | Medium | Clear documentation, CLI help |
| Deprecation warnings break CI | Low | Medium | Env var suppression option |
| Bundle download fails | Low | Low | Clear error messages, retry logic |

### Rollback Plan

Each PR is independent and can be reverted:

1. **Schema versioning:** Documents without `ontos_schema` still work
2. **Curation levels:** Documents without `curation_level` default to Level 2
3. **Deprecation warnings:** Can be suppressed via env var
4. **install.py:** Manual installation still works

---

## 10. Testing Strategy

### 10.1 Schema Module Tests

```python
# tests/test_schema.py

class TestSchemaDetection:
    def test_explicit_schema_version(self):
        fm = {'id': 'test', 'type': 'atom', 'ontos_schema': '2.2'}
        assert detect_schema_version(fm) == '2.2'

    def test_infer_v21_from_describes(self):
        fm = {'id': 'test', 'type': 'atom', 'describes': ['foo']}
        assert detect_schema_version(fm) == '2.1'

    def test_infer_v20_from_impacts(self):
        fm = {'id': 'test', 'type': 'log', 'impacts': ['foo']}
        assert detect_schema_version(fm) == '2.0'

    def test_infer_v10_minimal(self):
        fm = {'id': 'test', 'type': 'atom'}
        assert detect_schema_version(fm) == '1.0'


class TestSchemaCompatibility:
    def test_current_version_compatible(self):
        assert check_compatibility('2.2') == SchemaCompatibility.COMPATIBLE

    def test_older_version_upgradeable(self):
        assert check_compatibility('2.0') == SchemaCompatibility.UPGRADEABLE

    def test_future_version_incompatible(self):
        assert check_compatibility('3.0') == SchemaCompatibility.INCOMPATIBLE


class TestSchemaMigration:
    def test_migrate_v20_to_v22(self):
        fm = {'id': 'test', 'type': 'atom', 'status': 'active'}
        result = migrate_frontmatter(fm, '2.0', '2.2')
        assert result['ontos_schema'] == '2.2'
        assert result['curation_level'] == 0  # Inferred

    def test_migrate_preserves_existing_fields(self):
        fm = {'id': 'test', 'type': 'atom', 'depends_on': ['foo']}
        result = migrate_frontmatter(fm, '2.0', '2.2')
        assert result['depends_on'] == ['foo']
```

### 10.2 Curation Module Tests

```python
# tests/test_curation.py

class TestCurationLevelDetection:
    def test_explicit_level(self):
        fm = {'curation_level': 1}
        assert detect_curation_level(fm) == CurationLevel.STUB

    def test_infer_from_scaffold_status(self):
        fm = {'status': 'scaffold'}
        assert detect_curation_level(fm) == CurationLevel.SCAFFOLD

    def test_infer_full_from_depends_on(self):
        fm = {'type': 'atom', 'depends_on': ['mission']}
        assert detect_curation_level(fm) == CurationLevel.FULL


class TestCurationValidation:
    def test_level_0_allows_unknown_type(self):
        fm = {'id': 'test', 'type': 'unknown'}
        is_valid, _ = validate_at_level(fm, CurationLevel.SCAFFOLD)
        assert is_valid

    def test_level_1_rejects_unknown_type(self):
        fm = {'id': 'test', 'type': 'unknown', 'status': 'draft'}
        is_valid, issues = validate_at_level(fm, CurationLevel.STUB)
        assert not is_valid
        assert "not 'unknown'" in str(issues)

    def test_level_2_requires_depends_on(self):
        fm = {'id': 'test', 'type': 'atom', 'status': 'active'}
        is_valid, issues = validate_at_level(fm, CurationLevel.FULL)
        assert not is_valid
        assert 'depends_on' in str(issues)


class TestScaffoldGeneration:
    def test_scaffold_infers_type_from_path(self, tmp_path):
        filepath = tmp_path / 'docs' / 'strategy' / 'roadmap.md'
        filepath.parent.mkdir(parents=True)
        filepath.write_text('# Roadmap')

        scaffold = create_scaffold(filepath)
        assert scaffold['type'] == 'strategy'

    def test_scaffold_generates_valid_id(self, tmp_path):
        filepath = tmp_path / '2025-01-01 My Document.md'
        filepath.write_text('# Content')

        scaffold = create_scaffold(filepath)
        assert scaffold['id'] == 'doc_2025_01_01_my_document'
```

### 10.3 Install Tests

```python
# tests/test_install.py

class TestInstallVerification:
    def test_checksum_verification_passes(self, tmp_path):
        # Create a test bundle
        bundle = tmp_path / 'test.tar.gz'
        bundle.write_bytes(b'test content')

        expected = sha256_file(bundle)
        assert verify_checksum_internal(bundle, expected)

    def test_checksum_verification_fails(self, tmp_path):
        bundle = tmp_path / 'test.tar.gz'
        bundle.write_bytes(b'test content')

        wrong_checksum = 'a' * 64
        assert not verify_checksum_internal(bundle, wrong_checksum)


class TestInstallIdempotency:
    def test_detects_existing_installation(self, tmp_path):
        # Create .ontos directory
        (tmp_path / '.ontos' / 'scripts').mkdir(parents=True)
        (tmp_path / '.ontos' / 'scripts' / 'ontos_config_defaults.py').write_text(
            'ONTOS_VERSION = "2.8.6"'
        )

        result = detect_existing_installation_in(tmp_path)
        assert result['installed']
        assert result['version'] == '2.8.6'
```

---

## 11. Migration Guide

### 11.1 Upgrading from v2.8 to v2.9

#### For End Users

**Option A: Fresh Install (Recommended)**
```bash
# Backup your config
cp ontos_config.py ontos_config.py.bak

# Download and run installer (tag-pinned for reproducibility)
curl -sO https://raw.githubusercontent.com/ohjona/Project-Ontos/v2.9.0/install.py
python3 install.py --upgrade

# Restore your config (if needed)
cp ontos_config.py.bak ontos_config.py
```

**Option B: Manual Update**
```bash
python3 ontos.py update
```

#### For Custom Integrations

**Import Changes:**
```python
# v2.8 (deprecated in v2.9, removed in v3.0)
from ontos_lib import parse_frontmatter  # DeprecationWarning

# v2.9+ (recommended)
from ontos.core.frontmatter import parse_frontmatter
```

**New Fields:**
- `ontos_schema: "2.2"` — schema version (optional in v2.9)
- `curation_level: 0|1|2` — curation level (optional)

#### For CI/CD Pipelines

**Suppress deprecation warnings if needed:**
```bash
ONTOS_NO_DEPRECATION_WARNINGS=1 python3 ontos.py map --strict
```

### 11.2 Migrating Documents to Schema 2.2

```bash
# Check what needs migration
python3 ontos.py migrate --check

# Preview changes
python3 ontos.py migrate --dry-run

# Apply migrations
python3 ontos.py migrate --apply

# Commit changes
git add -A && git commit -m "chore: migrate documents to schema 2.2"
```

### 11.3 Adopting Curation Levels

**For new projects:**
```bash
# Start with scaffolds
python3 ontos.py scaffold

# Review and promote to stubs
# (edit each file, then run validation)
python3 ontos.py map --strict
```

**For existing projects:**
```bash
# Check curation status
python3 ontos.py maintain

# Documents are automatically Level 2 if they have depends_on
# No action required unless you want to add Level 0/1 docs
```

---

## 12. Implementation Progress

*This section tracks the actual implementation status of v2.9 features.*

### PR Status

| PR | Feature | Version | Status | Merged | Notes |
|----|---------|---------|--------|--------|-------|
| **#31** | Schema Versioning | v2.9.0 | ✅ MERGED | 2025-12-22 | See [3.5.1](#351-actual-api-pr-31) |
| **#33** | Curation Levels | v2.9.1 | ✅ MERGED | 2025-12-22 | See [4.12.1](#4121-actual-api-pr-33) |
| **#34** | Deprecation Warnings | v2.9.2 | ✅ MERGED | 2025-12-23 | Section 5 |
| **#35** | install.py Bootstrap | v2.9.3 | ✅ MERGED | 2025-12-23 | Section 2 |
| #36 | Documentation & Release | v2.9.4 | 🔄 NEXT | — | |

### Files Added/Modified in PR #31 (v2.9.0)

**New Files:**
- `.ontos/scripts/ontos/core/schema.py` (421 lines)
- `.ontos/scripts/ontos_migrate_schema.py` (325 lines)
- `.ontos/scripts/tests/test_schema.py` (307 lines, 42 tests)

**Modified Files:**
- `ontos.py` — Added `migrate` command + `schema` alias
- `.ontos/scripts/ontos_config_defaults.py` — Version bump to 2.9.0
- `tests/test_cli.py` — Updated command/alias counts
- `Ontos_CHANGELOG.md` — Added v2.9.0 entry

### Files Added/Modified in PR #33 (v2.9.1)

**New Files:**
- `.ontos/scripts/ontos/core/curation.py` (~490 lines)
- `.ontos/scripts/ontos_scaffold.py` (~230 lines)
- `.ontos/scripts/ontos_stub.py` (~200 lines)
- `.ontos/scripts/ontos_promote.py` (~440 lines)
- `.ontos/scripts/tests/test_curation.py` (~350 lines, 42+ tests)
- `.ontos/scripts/tests/test_promote.py` (~130 lines, 16+ tests)

**Modified Files:**
- `ontos.py` — Added `scaffold`, `stub`, `promote` commands + `curate` alias
- `.ontos/scripts/ontos_config_defaults.py` — Added `scaffold`, `pending_curation` to VALID_STATUS
- `.ontos/scripts/ontos_generate_context_map.py` — Added `[L0]`/`[L1]`/`[L2]` markers, `--strict` mode
- `.ontos/scripts/ontos_maintain.py` — Added curation level statistics
- `tests/test_cli.py` — Updated command/alias counts (11 commands, 13 aliases)

### Test Status

| Category | Count | Status |
|----------|-------|--------|
| Total tests | 397 | ✅ All passing |
| Root tests (`tests/`) | 285 | ✅ Original tests |
| Schema tests | 42 | ✅ New in PR #31 |
| Curation tests | 42+ | ✅ New in PR #33 |
| Promote tests | 16+ | ✅ New in PR #33 |
| Scripts tests | 112 | ✅ In `.ontos/scripts/tests/` |

### PR #34 Prerequisites (v2.9.2) — COMPLETE

All prerequisites completed in PR #34:

1. ✅ PR #31 merged (Schema Versioning)
2. ✅ PR #33 merged (Curation Levels)
3. ✅ Added `FutureWarning` to `ontos_lib.py` on import
4. ✅ Added `ONTOS_CLI_DISPATCH` env var to `ontos.py`
5. ✅ Added deprecation notices to direct script execution
6. ✅ Configured pytest warning filters

**Import pattern for PR #34:**
```python
# In ontos_lib.py (top of file)
import warnings
warnings.warn(
    "Importing from 'ontos_lib' is deprecated. "
    "Import from 'ontos.core' instead. "
    "This module will be removed in v3.0.",
    FutureWarning,  # Visible by default
    stacklevel=2
)
```

---

## 13. LLM Review Board Feedback

*Incorporated in v1.1.0*

### Reviewers

| Reviewer | Verdict | Key Contributions |
|----------|---------|-------------------|
| **Claude Opus 4.5** | Conditional Approval | YAML stdlib fix, checksum workflow, promote command |
| **Codex (GPT-5)** | Needs Revision | Supply chain trust, FutureWarning, validation modes |
| **Gemini** | Strong Approval | Config merge, .ontosignore, PyPI for v3.0 |

### Changes Incorporated (v1.0.0 → v1.1.0)

#### Critical (3 items)

| # | Change | Source | Section |
|---|--------|--------|---------|
| C1 | Replace yaml.dump() with stdlib serialization | Claude | 3.5, 4.10 |
| C2 | Update Q1 to Option B (independent versioning) | All | 7 |
| C3 | Fetch checksums from external checksums.json | All | 2.3 |

#### High Priority (8 items)

| # | Change | Source | Section |
|---|--------|--------|---------|
| H1 | Add `ontos.py promote` command | Claude, Gemini | 4.6 |
| H2 | Add validation modes (--strict vs --curated) | Codex | 4.8 |
| H3 | Display curation level in context map [L0]/[L1]/[L2] | Claude, Codex | 4.8 |
| H4 | Add retry logic with exponential backoff | Claude | 2.3 |
| H5 | Define upgrade semantics with config merge | Gemini | 2.6 |
| H6 | Use FutureWarning instead of DeprecationWarning | Codex | 5.2 |
| H7 | Scaffold defaults to --dry-run, require --apply | Gemini | 4.6 |
| H8 | Add .ontosignore support | Gemini | 4.7 |

#### Medium Priority (3 items)

| # | Change | Source | Section |
|---|--------|--------|---------|
| M1 | Fix type heuristics with word boundaries | Claude | 4.9 |
| M2 | Update risk assessment to HIGH | Claude | 1 |
| M3 | Use goal field on promotion (not discard) | Claude | 4.9 |

### Deferred to v3.0

| Item | Reason | Suggested By |
|------|--------|--------------|
| Cryptographic signing (GPG/minisign) | Requires key management infrastructure | Codex |
| PyPI distribution | Per Master Plan | Gemini |
| ruamel.yaml (comment preservation) | Violates zero-dependency invariant | Gemini |

*Note: Offline/air-gapped installation was implemented in PR #35 via `--bundle` and `--checksum` flags. See Section 2.*

---

## 14. Appendix: Master Plan References

### From Section II (Roadmap)

> **v2.9 install.py Bootstrap** (Distro): Single-file Python installer (curl-bootstrapped). Bridge — simulates V3 ease without PyPI overhead.
>
> **v2.9 Schema Versioning** (Arch): ontos_schema: 3.0 in frontmatter. Migration tools. Forward Compat — prepares for V3 transition.
>
> **v2.9 Curation Levels** (Growth): Level 0 (Scaffold) → Level 1 (Stub) → Level 2 (Full). Adoption — de-risks "Librarian's Wager."

### From ADR-002

> **Python Installer (install.py) over Shell (install.sh)**
> Decision: Accepted for V2.9.
> Rationale: Shell scripts are fragile (Windows vs Linux). Python is our native runtime. install.py can be signed/checksummed more reliably.

### From ADR-003

> **Graceful Curation (Levels 0-2)**
> Decision: Accepted.
> Rationale: To de-risk the "Librarian's Wager."
> - Level 0: Scaffold (Heuristic)
> - Level 1: Stub Log (User only provides Goal)
> - Level 2: Full Ontos (Dependencies + Concepts)

### Watch-outs Addressed (LLM Consensus)

| Feature | Watch-out | Source | Addressed |
|---------|-----------|--------|-----------|
| install.py | Security Risk — verify checksums (SHA256) | Gemini | Section 2.3 |
| install.py | Must be idempotent | Gemini | Section 2.6 |
| Schema Versioning | Define explicit migration path | Claude | Section 3.6 |
| Schema Versioning | V2 reading V3 should fail gracefully | Claude | Section 3.4 |
| Curation Levels | Strict validation rules per level | Gemini | Section 4.4 |
| Curation Levels | Level 1 must allow pending_curation | Gemini | Section 4.4 |

---

## 15. PR #36: Documentation & Release (v2.9.4)

*Added v1.5.0 per LLM Review Board v2.9.4 feedback (Claude, Codex, Gemini)*

**Goal:** Complete v2.9 release with comprehensive documentation.

**Version Target:** 2.9.4 (documentation-only release)

### 15.1 Tasks

| Task | Description | File | Priority |
|------|-------------|------|----------|
| 36.1 | Fix config merge write bug | `install.py` | MEDIUM |
| 36.2 | Create install.py unit tests | `tests/test_install.py` (new) | MEDIUM |
| 36.3 | Update Manual to v2.9 | `docs/reference/Ontos_Manual.md` | HIGH |
| 36.4 | Update Agent Instructions | `docs/reference/Ontos_Agent_Instructions.md` | MEDIUM |
| 36.5 | Add curl install to README | `README.md` | HIGH |
| 36.6 | Version bump to 2.9.4 | `ontos_config_defaults.py` | HIGH |
| 36.7 | Add CHANGELOG entry | `Ontos_CHANGELOG.md` | MEDIUM |
| 36.8 | Final test suite run | All tests | HIGH |
| 36.9 | Update this plan status | This file | LOW |

### 15.2 Task Details

#### 36.1 Config Merge Write Bug

**Problem:** Lines 528-532 of `install.py` compute merged config but don't persist it.

**Solution:** Add `write_user_config()` function that reads existing `ontos_config.py`, updates values, preserves comments.

#### 36.2 Install.py Unit Tests

Create `tests/test_install.py` with:
- Path traversal security tests (POSIX + Windows)
- Checksum verification tests
- Installation detection tests

Expected: ~15-20 new tests.

#### 36.3-36.5 Documentation Updates

**README.md:**
```markdown
## Quick Start

### Recommended: Curl Bootstrap
```bash
curl -sO https://raw.githubusercontent.com/ohjona/Project-Ontos/v2.9.4/install.py
python3 install.py
```
```

**Ontos_Manual.md:** Add Section 9 covering:
- Schema Versioning (v2.9.0)
- Curation Levels (v2.9.1)
- Deprecation Warnings (v2.9.2)
- install.py Bootstrap (v2.9.3)

**Agent Instructions:** Add "Install Ontos" and "Upgrade Ontos" commands.

### 15.3 Exit Criteria

| Criterion | Verification | Expected |
|-----------|--------------|----------|
| Tests pass | `pytest tests/ .ontos/scripts/tests/` | 410+ tests, 0 failures |
| New tests exist | `pytest tests/test_install.py -v` | ~15 tests |
| Context map valid | `python3 ontos.py map --strict` | No errors |
| Version correct | `grep ONTOS_VERSION ontos_config_defaults.py` | "2.9.4" |
| README has curl | `grep "curl -sO" README.md` | Match found |
| Manual is v2.9 | `grep "Ontos Manual v2.9" Ontos_Manual.md` | Match found |

### 15.4 Out of Scope

| Item | Reason | Deferred To |
|------|--------|-------------|
| Release workflow (.github/workflows/release.yml) | Not blocking; manual release works | v3.0 |
| PyPI distribution | Per Master Plan | v3.0 |
| Comprehensive install integration tests | Would require mock HTTP | v3.0 |

### 15.5 Risk Analysis

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Config write breaks existing installs | Low | Medium | Test with real upgrade scenario |
| Documentation changes break examples | Low | Low | Run examples after updating |
| Test imports fail on install.py | Medium | Low | Careful sys.path management |

---

## Revision History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2025-12-22 | Initial draft |
| 1.1.0 | 2025-12-22 | Incorporated LLM Review Board Round 1 feedback (14 changes) |
| 1.2.0 | 2025-12-22 | Incorporated LLM Review Board Round 2 feedback (13 changes) |
| 1.3.0 | 2025-12-22 | Incorporated LLM Review Board Round 3 feedback (4 changes) |
| 1.4.0 | 2025-12-23 | Updated Section 12 to mark PRs #34, #35 as merged |
| **1.5.0** | **2025-12-24** | **Incorporated LLM Review Board v2.9.4 feedback (see below)** |

### Changes in v1.5.0

| # | Change | Source | Section |
|---|--------|--------|---------|
| 1 | Update status to "v2.9.4 next" | All reviewers | Header |
| 2 | Update test count from 390 to 397 | All reviewers | 12 |
| 3 | Mark PR #34 prerequisites as complete | All reviewers | 12 |
| 4 | Add Section 15 for v2.9.4 implementation | Claude | 15 (new) |
| 5 | Add deprecation suppression policy clarification | Codex | 5.7 (new) |
| 6 | Add internal-only scripts list | Codex | 5.8 (new) |
| 7 | Remove offline install from deferred (implemented) | All reviewers | 13 |
| 8 | Fix Section 5.5 duplicate numbering → 5.6 | Claude | 5.6 |

### Changes in v1.4.0

| # | Change | Source | Section |
|---|--------|--------|---------|
| 1 | Mark PR #34 (Deprecation Warnings) as MERGED | Post-merge | 12 |
| 2 | Mark PR #35 (install.py Bootstrap) as MERGED | Post-merge | 12 |
| 3 | Update current state to v2.9.3 | Post-merge | 1 |

### Changes in v1.3.0

| # | Change | Source | Section |
|---|--------|--------|---------|
| 1 | Tag-align checksums.json URL (fetch from tag, not main) | Codex R3 | 2.3, 2.4 |
| 2 | Add bundle manifest.json for version-aware verification | Codex R3 | 2.4, 2.5 |
| 3 | Define `.install_incomplete` behavior on re-run | Codex R3 | 2.4 |
| 4 | Implement `--latest` flag with GitHub API | Codex R3 | 2.4 |

### Changes in v1.2.0

| # | Change | Source | Section |
|---|--------|--------|---------|
| 1 | Add symlink check to `extract_bundle()` | Claude R2 | 2.4 |
| 2 | Fix scaffold `--apply` flag (dry-run default) | Claude R2 | 4.10 |
| 3 | Add `ontos_promote.py` implementation | Claude R2 | 4.11 |
| 4 | Fix document section numbering | Claude R2 | TOC |
| 5 | Add `parse_version` validation | Claude R2 | 3.5 |
| 6 | Use tag-pinned URLs in examples | Codex R2 | 2.2, 2.4, 11 |
| 7 | Add schema specification table | Codex R2 | 3.2 |
| 8 | Define strict/curated validation semantics | Codex R2 | 4.8 |
| 9 | Add CLI deprecation notice mechanism | Codex R2 | 5.4 |
| 10 | Integrate sentinel pattern in `install()` | Gemini R2 | 2.4 |
| 11 | Add goal→summary seeding to promote | Gemini R2 | 4.11 |
| 12 | Update EXPECTED_FILES for v2.9 modules | Claude R2 | 2.4 |
| 13 | Add integrity scope note | Codex R2 | 2.3 |

---

*End of v2.9 Implementation Plan v1.5.0*

*Status: APPROVED — v2.9.4 next*
