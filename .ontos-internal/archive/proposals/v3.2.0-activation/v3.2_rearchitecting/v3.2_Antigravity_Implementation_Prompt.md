---
id: v3_2_antigravity_implementation_prompt
type: strategy
status: active
depends_on: [v3_2_re_architecture_support_implementation_spec]
concepts: [migration, architecture, implementation-prompt]
---

# Antigravity Implementation Prompt: v3.2 Re-Architecture Support

**Role:** Antigravity (Developer)
**Phase:** C.2 — Implementation
**Version:** 3.2
**Date:** 2026-01-28

---

## Overview

**What you're building:** Re-Architecture Support commands for Ontos — bulk data export, migration analysis, and convenience workflows that help users migrate projects to new technology stacks.

**Risk Level:** LOW (additive commands, no breaking changes)

**Estimated Scope:**
- 4 new command modules
- 2 new core modules
- 1 CLI modification (first subcommand pattern)
- 4 new test files
- 3 documentation files

---

## Pre-Implementation Checklist

Before writing any code:

- [ ] Create feature branch: `git checkout -b feature/v3.2-rearch-support`
- [ ] Verify tests pass: `pytest tests/ -v`
- [ ] Read this prompt completely
- [ ] Verify you're on branch `main` at commit `bddd2e0`

---

## Architecture Constraints

**Must follow (from Constitution):**
- Zero external dependencies — Python stdlib only
- Functional core, imperative shell — core modules never call print() or input()
- Local-first — all data stays in repo

**Patterns to match:**
- Command options as `@dataclass` (see `ontos/commands/stub.py` lines 14-23)
- Commands return `Tuple[int, str]` (exit code, message)
- CLI handlers in `cli.py` use lazy imports (inside `_cmd_*` functions)
- JSON output via `emit_json()` from `ontos.ui.json_output`

---

## Current Codebase State

**CLI Registration (cli.py):**
- Lines 49-97: `create_parser()` with command registrations
- Lines 82-95: All `_register_*()` calls
- Lines 181-188: Current `_register_export()` — **will be replaced**
- Lines 482-507: Current `_cmd_export()` — delegates to agents, **will be replaced**

**Existing export.py (ontos/commands/export.py):**
- Lines 13-17: `ExportOptions` dataclass
- Lines 20-41: `CLAUDE_MD_TEMPLATE`
- Lines 57-93: `export_command()` function — generates CLAUDE.md
- **Note:** This is currently NOT wired into CLI (CLI delegates to agents instead)

**Core modules:**
- `ontos/core/types.py`: `DocumentData`, `DocumentType`, `DocumentStatus` enums
- `ontos/core/graph.py`: `DependencyGraph`, `build_graph()`, `detect_cycles()`
- `ontos/core/frontmatter.py`: `parse_frontmatter()`, normalization functions
- `ontos/io/files.py`: `scan_documents()`, `load_document_from_content()`

---

## Task Sequence

Complete tasks in order. Commit after each task.

---

### Task 1: Create Snapshot Primitive

**Purpose:** Single scanning/parsing layer used by all export commands.

**Files:**
- `ontos/core/snapshot.py` — CREATE

**Code:**

```python
"""
Snapshot primitive for document collection.

Creates an immutable snapshot of all documents at a point in time.
Used by export and migration commands.
"""

from __future__ import annotations
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from ontos.core.types import DocumentData, ValidationResult
from ontos.core.graph import DependencyGraph, build_graph
from ontos.core.validation import ValidationOrchestrator


@dataclass
class SnapshotFilters:
    """Filters for document selection."""
    types: Optional[List[str]] = None
    status: Optional[List[str]] = None
    concepts: Optional[List[str]] = None


@dataclass
class DocumentSnapshot:
    """Immutable snapshot of all documents at a point in time."""
    timestamp: datetime
    project_root: Path
    documents: Dict[str, DocumentData]
    graph: DependencyGraph
    validation_result: ValidationResult
    git_commit: Optional[str] = None
    ontos_version: str = ""

    @property
    def by_type(self) -> Dict[str, List[DocumentData]]:
        """Group documents by type."""
        result: Dict[str, List[DocumentData]] = {}
        for doc in self.documents.values():
            doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
            if doc_type not in result:
                result[doc_type] = []
            result[doc_type].append(doc)
        return result

    @property
    def by_status(self) -> Dict[str, List[DocumentData]]:
        """Group documents by status."""
        result: Dict[str, List[DocumentData]] = {}
        for doc in self.documents.values():
            doc_status = doc.status.value if hasattr(doc.status, 'value') else str(doc.status)
            if doc_status not in result:
                result[doc_status] = []
            result[doc_status].append(doc)
        return result


def _matches_filter(doc: DocumentData, filters: Optional[SnapshotFilters]) -> bool:
    """Check if document matches filter criteria."""
    if filters is None:
        return True

    # Type filter
    if filters.types:
        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
        if doc_type not in filters.types:
            return False

    # Status filter
    if filters.status:
        doc_status = doc.status.value if hasattr(doc.status, 'value') else str(doc.status)
        if doc_status not in filters.status:
            return False

    # Concept filter
    if filters.concepts:
        doc_concepts = set(doc.tags)
        if not doc_concepts.intersection(set(filters.concepts)):
            return False

    return True


def create_snapshot(
    root: Path,
    include_content: bool = True,
    filters: Optional[SnapshotFilters] = None,
    git_commit_provider: Optional[callable] = None,
) -> DocumentSnapshot:
    """
    Create a snapshot of all documents.

    Args:
        root: Project root directory
        include_content: Whether to include document content
        filters: Optional filters (type, status, concept)
        git_commit_provider: Optional callback to get git commit hash

    Returns:
        Immutable DocumentSnapshot
    """
    import ontos
    from ontos.io.config import load_project_config
    from ontos.io.files import scan_documents, load_document_from_content
    from ontos.io.yaml import parse_frontmatter_content

    # Load config
    config = load_project_config(repo_root=root)

    # Determine docs directory
    docs_dir = root / config.paths.docs_dir
    internal_dir = root / ".ontos-internal"

    scan_dirs = []
    if docs_dir.exists():
        scan_dirs.append(docs_dir)
    if internal_dir.exists():
        scan_dirs.append(internal_dir)

    # Scan documents
    skip_patterns = config.scanning.skip_patterns if config.scanning else ["_template.md", "archive/*"]
    doc_paths = scan_documents(scan_dirs, skip_patterns=skip_patterns)

    # Load documents
    documents: Dict[str, DocumentData] = {}
    for path in doc_paths:
        try:
            content = path.read_text(encoding='utf-8')
            doc = load_document_from_content(path, content, parse_frontmatter_content)

            # Apply filters
            if _matches_filter(doc, filters):
                # Optionally strip content
                if not include_content:
                    doc = DocumentData(
                        id=doc.id,
                        type=doc.type,
                        status=doc.status,
                        filepath=doc.filepath,
                        frontmatter=doc.frontmatter,
                        content="",  # Strip content
                        depends_on=doc.depends_on,
                        impacts=doc.impacts,
                        tags=doc.tags,
                        aliases=doc.aliases,
                    )
                documents[doc.id] = doc
        except Exception:
            # Skip unparseable files
            continue

    # Build graph
    graph, _ = build_graph(documents)

    # Run validation
    orchestrator = ValidationOrchestrator(documents, {})
    validation_result = orchestrator.validate_all()

    # Get git commit if provider given
    git_commit = None
    if git_commit_provider:
        try:
            git_commit = git_commit_provider()
        except Exception:
            pass

    return DocumentSnapshot(
        timestamp=datetime.now(),
        project_root=root,
        documents=documents,
        graph=graph,
        validation_result=validation_result,
        git_commit=git_commit,
        ontos_version=ontos.__version__,
    )
```

**Test:** Create `tests/core/test_snapshot.py`

```python
"""Tests for snapshot primitive."""

import pytest
from pathlib import Path
from ontos.core.snapshot import create_snapshot, SnapshotFilters, DocumentSnapshot


class TestCreateSnapshot:
    """Tests for create_snapshot function."""

    def test_create_snapshot_empty_project(self, tmp_path):
        """Snapshot of empty project has no documents."""
        # Create minimal config
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        (tmp_path / "docs").mkdir()

        snapshot = create_snapshot(tmp_path)

        assert isinstance(snapshot, DocumentSnapshot)
        assert len(snapshot.documents) == 0

    def test_create_snapshot_with_documents(self, tmp_path):
        """Snapshot includes parsed documents."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        doc = docs / "test.md"
        doc.write_text("""---
id: test_doc
type: atom
status: active
---
# Test Document
Content here.
""")

        snapshot = create_snapshot(tmp_path)

        assert "test_doc" in snapshot.documents
        assert snapshot.documents["test_doc"].content == "# Test Document\nContent here.\n"

    def test_create_snapshot_no_content(self, tmp_path):
        """Snapshot without content strips document bodies."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        doc = docs / "test.md"
        doc.write_text("""---
id: test_doc
type: atom
status: active
---
# Test Document
""")

        snapshot = create_snapshot(tmp_path, include_content=False)

        assert "test_doc" in snapshot.documents
        assert snapshot.documents["test_doc"].content == ""

    def test_create_snapshot_type_filter(self, tmp_path):
        """Filter by document type."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "kernel.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")
        (docs / "atom.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        filters = SnapshotFilters(types=["kernel"])
        snapshot = create_snapshot(tmp_path, filters=filters)

        assert "k1" in snapshot.documents
        assert "a1" not in snapshot.documents


class TestSnapshotProperties:
    """Tests for DocumentSnapshot properties."""

    def test_by_type_groups_documents(self, tmp_path):
        """by_type property groups documents correctly."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "k1.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")
        (docs / "k2.md").write_text("---\nid: k2\ntype: kernel\nstatus: active\n---\n")
        (docs / "a1.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        snapshot = create_snapshot(tmp_path)

        assert len(snapshot.by_type.get("kernel", [])) == 2
        assert len(snapshot.by_type.get("atom", [])) == 1
```

**Commit:**
```
feat(core): add snapshot primitive

- Add create_snapshot() factory function
- Add DocumentSnapshot and SnapshotFilters dataclasses
- Add filtering by type, status, concept
- Add by_type and by_status computed properties
```

---

### Task 2: Create Migration Classification Module

**Purpose:** Classification algorithm for migration safety.

**Files:**
- `ontos/core/migration.py` — CREATE

**Code:**

```python
"""
Migration classification logic.

Classifies documents as safe/review/rewrite based on atom dependencies.
"""

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Set

from ontos.core.snapshot import DocumentSnapshot
from ontos.core.graph import DependencyGraph


# Classification severity order (for downgrade detection)
SEVERITY_ORDER = {"safe": 0, "review": 1, "rewrite": 2}


@dataclass
class MigrationClassification:
    """Classification result for a single document."""
    id: str
    doc_type: str
    path: str
    inferred_status: str  # 'safe', 'review', 'rewrite'
    effective_status: str
    override: Optional[str] = None
    override_reason: Optional[str] = None
    atom_dependencies: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


@dataclass
class MigrationReport:
    """Complete migration classification report."""
    classifications: Dict[str, MigrationClassification]
    summary: Dict[str, int]  # safe/review/rewrite counts
    warnings: List[Dict[str, str]]  # Global warnings


def _find_transitive_atom_deps(
    doc_id: str,
    graph: DependencyGraph,
    atoms: Set[str],
    visited: Optional[Set[str]] = None
) -> Set[str]:
    """Find all atoms this document depends on (transitively)."""
    if visited is None:
        visited = set()

    if doc_id in visited:
        return set()  # Cycle detected
    visited.add(doc_id)

    result = set()
    for dep_id in graph.edges.get(doc_id, []):
        if dep_id in atoms:
            result.add(dep_id)
        # Recurse into dependencies
        result.update(_find_transitive_atom_deps(dep_id, graph, atoms, visited))

    return result


def classify_documents(snapshot: DocumentSnapshot) -> MigrationReport:
    """
    Classify all documents for migration.

    Algorithm:
    1. Identify all atoms
    2. Build transitive atom dependency map
    3. Classify each document:
       - type == 'atom' → inferred = 'rewrite'
       - has transitive atom dependency → inferred = 'review'
       - otherwise → inferred = 'safe'
    4. Apply overrides, emit warnings for downgrades
    """
    # Step 1: Identify all atoms
    atoms = set()
    for doc_id, doc in snapshot.documents.items():
        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
        if doc_type == "atom":
            atoms.add(doc_id)

    # Step 2 & 3: Classify each document
    classifications: Dict[str, MigrationClassification] = {}
    global_warnings: List[Dict[str, str]] = []

    for doc_id, doc in snapshot.documents.items():
        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)

        # Find transitive atom dependencies
        atom_deps = list(_find_transitive_atom_deps(doc_id, snapshot.graph, atoms))

        # Determine inferred status
        if doc_type == "atom":
            inferred = "rewrite"
        elif atom_deps:
            inferred = "review"
        else:
            inferred = "safe"

        # Check for override in frontmatter
        override = doc.frontmatter.get("migration_status")
        override_reason = doc.frontmatter.get("migration_status_reason")

        # Validate override value
        if override and override not in ("safe", "review", "rewrite"):
            global_warnings.append({
                "id": doc_id,
                "type": "invalid_override",
                "message": f"Invalid migration_status '{override}', ignoring"
            })
            override = None

        # Determine effective status
        effective = override if override else inferred

        # Warn on downgrade
        warnings = []
        if override and SEVERITY_ORDER.get(override, 0) < SEVERITY_ORDER.get(inferred, 0):
            warning_msg = f"Override downgrades inferred classification from '{inferred}' to '{override}'"
            warnings.append(warning_msg)
            global_warnings.append({
                "id": doc_id,
                "type": "override_downgrade",
                "message": warning_msg
            })

        classifications[doc_id] = MigrationClassification(
            id=doc_id,
            doc_type=doc_type,
            path=str(doc.filepath),
            inferred_status=inferred,
            effective_status=effective,
            override=override,
            override_reason=override_reason,
            atom_dependencies=sorted(atom_deps),
            warnings=warnings,
        )

    # Build summary
    summary = {"safe": 0, "review": 0, "rewrite": 0}
    for c in classifications.values():
        summary[c.effective_status] = summary.get(c.effective_status, 0) + 1

    return MigrationReport(
        classifications=classifications,
        summary=summary,
        warnings=global_warnings,
    )
```

**Test:** Create `tests/core/test_migration.py`

```python
"""Tests for migration classification."""

import pytest
from pathlib import Path
from ontos.core.snapshot import create_snapshot
from ontos.core.migration import classify_documents, MigrationReport


class TestClassifyDocuments:
    """Tests for classify_documents function."""

    def test_atom_classified_as_rewrite(self, tmp_path):
        """Atom documents are classified as rewrite."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "atom.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        assert report.classifications["a1"].inferred_status == "rewrite"
        assert report.classifications["a1"].effective_status == "rewrite"

    def test_kernel_classified_as_safe(self, tmp_path):
        """Kernel documents are classified as safe."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "kernel.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        assert report.classifications["k1"].inferred_status == "safe"

    def test_doc_depending_on_atom_classified_as_review(self, tmp_path):
        """Documents depending on atoms are classified as review."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "atom.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")
        (docs / "product.md").write_text("---\nid: p1\ntype: product\nstatus: active\ndepends_on: [a1]\n---\n")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        assert report.classifications["p1"].inferred_status == "review"
        assert "a1" in report.classifications["p1"].atom_dependencies

    def test_override_respected(self, tmp_path):
        """migration_status override is respected."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "atom.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")
        (docs / "product.md").write_text("""---
id: p1
type: product
status: active
depends_on: [a1]
migration_status: safe
migration_status_reason: API is abstract enough
---
""")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        assert report.classifications["p1"].inferred_status == "review"
        assert report.classifications["p1"].effective_status == "safe"
        assert report.classifications["p1"].override == "safe"

    def test_downgrade_warning(self, tmp_path):
        """Downgrade override emits warning."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "atom.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")
        (docs / "product.md").write_text("""---
id: p1
type: product
status: active
depends_on: [a1]
migration_status: safe
---
""")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        # Should have warning about downgrade
        assert len(report.warnings) > 0
        assert any(w["type"] == "override_downgrade" for w in report.warnings)

    def test_summary_counts(self, tmp_path):
        """Summary has correct counts."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()

        (docs / "k1.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")
        (docs / "k2.md").write_text("---\nid: k2\ntype: kernel\nstatus: active\n---\n")
        (docs / "a1.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        snapshot = create_snapshot(tmp_path)
        report = classify_documents(snapshot)

        assert report.summary["safe"] == 2
        assert report.summary["rewrite"] == 1
```

**Commit:**
```
feat(core): add migration classification logic

- Add classify_documents() function
- Add MigrationClassification and MigrationReport dataclasses
- Implement transitive atom dependency detection
- Add override support with downgrade warnings
```

---

### Task 3: Create Export Data Command

**Purpose:** Bulk export documents as structured JSON.

**Files:**
- `ontos/commands/export_data.py` — CREATE

**Code:**

```python
"""
Export data command — bulk document export to JSON.
"""

from __future__ import annotations
import hashlib
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

from ontos.core.snapshot import create_snapshot, SnapshotFilters, DocumentSnapshot
from ontos.core.migration import classify_documents
from ontos.io.files import find_project_root


@dataclass
class ExportDataOptions:
    """Options for export data command."""
    output_path: Optional[Path] = None
    types: Optional[str] = None  # Comma-separated
    status: Optional[str] = None  # Comma-separated
    concepts: Optional[str] = None  # Comma-separated
    no_content: bool = False
    deterministic: bool = False
    force: bool = False
    quiet: bool = False
    json_output: bool = False


def _parse_csv(value: Optional[str]) -> Optional[List[str]]:
    """Parse comma-separated string to list."""
    if not value:
        return None
    return [v.strip() for v in value.split(",") if v.strip()]


def _compute_content_hash(content: str) -> str:
    """Compute SHA256 hash of content."""
    return f"sha256:{hashlib.sha256(content.encode('utf-8')).hexdigest()[:16]}"


def _snapshot_to_json(
    snapshot: DocumentSnapshot,
    filters: Optional[SnapshotFilters],
    deterministic: bool = False,
) -> Dict[str, Any]:
    """Convert snapshot to JSON-serializable dict."""
    import ontos

    # Get migration classifications
    report = classify_documents(snapshot)

    # Build documents list
    documents = []
    for doc_id in sorted(snapshot.documents.keys()) if deterministic else snapshot.documents.keys():
        doc = snapshot.documents[doc_id]
        classification = report.classifications.get(doc_id)

        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
        doc_status = doc.status.value if hasattr(doc.status, 'value') else str(doc.status)

        doc_dict = {
            "id": doc.id,
            "type": doc_type,
            "status": doc_status,
            "path": str(doc.filepath),
            "depends_on": sorted(doc.depends_on) if deterministic else doc.depends_on,
            "concepts": sorted(doc.tags) if deterministic else doc.tags,
            "decision_summary": doc.frontmatter.get("decision_summary"),
            "decision_rationale": doc.frontmatter.get("decision_rationale"),
            "alternatives_rejected": doc.frontmatter.get("alternatives_rejected"),
            "migration_status": doc.frontmatter.get("migration_status"),
            "migration_status_reason": doc.frontmatter.get("migration_status_reason"),
            "inferred_migration_status": classification.inferred_status if classification else None,
            "effective_migration_status": classification.effective_status if classification else None,
            "content": doc.content if doc.content else None,
            "content_hash": _compute_content_hash(doc.content) if doc.content else None,
        }
        documents.append(doc_dict)

    # Build graph edges
    edges = []
    for doc_id in sorted(snapshot.graph.edges.keys()) if deterministic else snapshot.graph.edges.keys():
        for dep_id in sorted(snapshot.graph.edges[doc_id]) if deterministic else snapshot.graph.edges[doc_id]:
            edges.append({
                "from": doc_id,
                "to": dep_id,
                "type": "depends_on"
            })

    # Build provenance
    provenance = {
        "exported_at": "deterministic" if deterministic else datetime.now().isoformat(),
        "ontos_version": ontos.__version__,
        "git_commit": "deterministic" if deterministic else snapshot.git_commit,
        "project_root": str(snapshot.project_root),
    }

    # Build summary
    by_type: Dict[str, int] = {}
    by_status: Dict[str, int] = {}
    for doc in snapshot.documents.values():
        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
        doc_status = doc.status.value if hasattr(doc.status, 'value') else str(doc.status)
        by_type[doc_type] = by_type.get(doc_type, 0) + 1
        by_status[doc_status] = by_status.get(doc_status, 0) + 1

    result = {
        "schema_version": "ontos-export-v1",
        "provenance": provenance,
        "filters": {
            "types": filters.types if filters else None,
            "status": filters.status if filters else None,
            "concepts": filters.concepts if filters else None,
        },
        "summary": {
            "total_documents": len(documents),
            "by_type": dict(sorted(by_type.items())) if deterministic else by_type,
            "by_status": dict(sorted(by_status.items())) if deterministic else by_status,
        },
        "documents": documents,
        "graph": {
            "nodes": sorted(list(snapshot.graph.nodes.keys())) if deterministic else list(snapshot.graph.nodes.keys()),
            "edges": edges,
        },
    }

    return result


def export_data_command(options: ExportDataOptions) -> Tuple[int, str]:
    """
    Export documents as structured JSON.

    Returns:
        Tuple of (exit_code, message)
    """
    try:
        root = find_project_root()
    except Exception as e:
        return 1, f"Error: {e}"

    # Check output file
    if options.output_path:
        if options.output_path.exists() and not options.force:
            return 1, f"Error: Output file exists: {options.output_path}. Use --force to overwrite."

    # Build filters
    filters = SnapshotFilters(
        types=_parse_csv(options.types),
        status=_parse_csv(options.status),
        concepts=_parse_csv(options.concepts),
    )

    # Create snapshot
    snapshot = create_snapshot(
        root=root,
        include_content=not options.no_content,
        filters=filters,
    )

    # Convert to JSON
    data = _snapshot_to_json(snapshot, filters, options.deterministic)

    # Serialize
    if options.deterministic:
        json_str = json.dumps(data, indent=2, sort_keys=True)
    else:
        json_str = json.dumps(data, indent=2)

    # Output
    if options.output_path:
        options.output_path.parent.mkdir(parents=True, exist_ok=True)
        options.output_path.write_text(json_str, encoding='utf-8')
        return 0, f"Exported {len(snapshot.documents)} documents to {options.output_path}"
    else:
        # Print to stdout (handled by CLI layer)
        return 0, json_str
```

**Commit:**
```
feat(export): add export data command

- Add ExportDataOptions dataclass
- Add export_data_command() function
- Implement JSON serialization with schema
- Support filters, deterministic mode, no-content mode
```

---

### Task 4: Refactor Export Claude Command

**Purpose:** Move CLAUDE.md generation to dedicated module.

**Files:**
- `ontos/commands/export_claude.py` — CREATE (copy from export.py lines 13-93, rename)

**Code:**

```python
"""
Export claude command — generate CLAUDE.md file.

Refactored from export.py for v3.2 subcommand structure.
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple

from ontos.io.files import find_project_root


CLAUDE_MD_TEMPLATE = '''# CLAUDE.md

## Ontos Activation

This project uses **Ontos** for documentation management.

At the start of every session:
1. Run `ontos map` to generate the context map
2. Read `Ontos_Context_Map.md` to understand the project documentation structure

When ending a session:
3. Run `ontos log` to record your work

## What is Ontos?

Ontos is a local-first documentation management system that:
- Maintains a context map of all project documentation
- Tracks documentation dependencies and status
- Ensures documentation stays synchronized with code changes

For more information, see `docs/reference/Ontos_Manual.md`.
'''


@dataclass
class ExportClaudeOptions:
    """Options for export claude command."""
    output_path: Optional[Path] = None
    force: bool = False
    quiet: bool = False
    json_output: bool = False


def export_claude_command(options: ExportClaudeOptions) -> Tuple[int, str]:
    """
    Generate CLAUDE.md file.

    Returns:
        Tuple of (exit_code, message)

    Exit Codes:
        0: Success
        1: File exists (use --force)
        2: Configuration error
    """
    try:
        repo_root = find_project_root()
    except Exception as e:
        return 2, f"Configuration error: {e}"

    output_path = options.output_path or repo_root / "CLAUDE.md"

    # Path safety validation
    try:
        resolved_output = output_path.resolve()
        resolved_root = repo_root.resolve()
        resolved_output.relative_to(resolved_root)
    except ValueError:
        return 2, f"Error: Output path must be within repository root ({repo_root})"

    if output_path.exists() and not options.force:
        return 1, f"CLAUDE.md already exists at {output_path}. Use --force to overwrite."

    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(CLAUDE_MD_TEMPLATE, encoding="utf-8")
    except Exception as e:
        return 2, f"Error writing file: {e}"

    return 0, f"Created {output_path}"
```

**Commit:**
```
refactor(export): extract export claude to dedicated module

- Create export_claude.py with ExportClaudeOptions
- Copy CLAUDE_MD_TEMPLATE from export.py
- Identical behavior to original export command
```

---

### Task 5: Create Migration Report Command

**Purpose:** Generate migration analysis report.

**Files:**
- `ontos/commands/migration_report.py` — CREATE

**Code:**

```python
"""
Migration report command — analyze documents for migration safety.
"""

from __future__ import annotations
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple, Dict, Any

from ontos.core.snapshot import create_snapshot
from ontos.core.migration import classify_documents, MigrationReport
from ontos.io.files import find_project_root


@dataclass
class MigrationReportOptions:
    """Options for migration-report command."""
    output_path: Optional[Path] = None
    format: str = "md"  # md or json
    force: bool = False
    quiet: bool = False
    json_output: bool = False


def _generate_markdown_report(report: MigrationReport, project_name: str) -> str:
    """Generate markdown migration report."""
    import ontos

    lines = [
        "# Migration Report",
        "",
        f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Project:** {project_name}",
        f"**Ontos Version:** {ontos.__version__}",
        "",
        "---",
        "",
        "## Summary",
        "",
        "| Classification | Count | Action |",
        "|----------------|-------|--------|",
        f"| Safe to migrate | {report.summary.get('safe', 0)} | Copy to new project |",
        f"| Needs review | {report.summary.get('review', 0)} | Update references |",
        f"| Needs rewrite | {report.summary.get('rewrite', 0)} | Preserve intent, reimplement |",
        "",
        "---",
        "",
    ]

    # Safe documents
    safe_docs = [c for c in report.classifications.values() if c.effective_status == "safe"]
    if safe_docs:
        lines.extend([
            "## Safe to Migrate",
            "",
            "These documents have no dependencies on implementation-specific atoms.",
            "",
            "| ID | Type | Path |",
            "|----|------|------|",
        ])
        for c in sorted(safe_docs, key=lambda x: x.id):
            lines.append(f"| {c.id} | {c.doc_type} | {c.path} |")
        lines.extend(["", "---", ""])

    # Review documents
    review_docs = [c for c in report.classifications.values() if c.effective_status == "review"]
    if review_docs:
        lines.extend([
            "## Needs Review",
            "",
            "These documents depend on atoms (directly or indirectly).",
            "",
            "| ID | Type | Atom Dependencies | Reason |",
            "|----|------|-------------------|--------|",
        ])
        for c in sorted(review_docs, key=lambda x: x.id):
            deps = ", ".join(c.atom_dependencies) if c.atom_dependencies else "-"
            reason = "Depends on atom" if c.atom_dependencies else "-"
            lines.append(f"| {c.id} | {c.doc_type} | {deps} | {reason} |")
        lines.extend(["", "---", ""])

    # Rewrite documents
    rewrite_docs = [c for c in report.classifications.values() if c.effective_status == "rewrite"]
    if rewrite_docs:
        lines.extend([
            "## Needs Rewrite",
            "",
            "These are atoms—implementation-specific documents.",
            "",
            "| ID | Type | Intent to Preserve |",
            "|----|------|-------------------|",
        ])
        for c in sorted(rewrite_docs, key=lambda x: x.id):
            lines.append(f"| {c.id} | {c.doc_type} | (extract from content) |")
        lines.extend(["", "---", ""])

    # Override warnings
    override_warnings = [w for w in report.warnings if w.get("type") == "override_downgrade"]
    if override_warnings:
        lines.extend([
            "## Override Warnings",
            "",
            "Documents where manual override downgrades risk:",
            "",
            "| ID | Inferred | Override | Reason |",
            "|----|----------|----------|--------|",
        ])
        for w in override_warnings:
            c = report.classifications.get(w["id"])
            if c:
                lines.append(f"| {c.id} | {c.inferred_status} | {c.override} | {c.override_reason or '-'} |")
        lines.extend([
            "",
            "**Warning:** Override downgrades inferred classification. Verify this is intentional.",
        ])

    return "\n".join(lines)


def _generate_json_report(report: MigrationReport, project_root: Path) -> Dict[str, Any]:
    """Generate JSON migration report."""
    import ontos

    classifications = []
    for c in sorted(report.classifications.values(), key=lambda x: x.id):
        classifications.append({
            "id": c.id,
            "type": c.doc_type,
            "path": c.path,
            "inferred_migration_status": c.inferred_status,
            "effective_migration_status": c.effective_status,
            "override": c.override,
            "override_reason": c.override_reason,
            "atom_dependencies": c.atom_dependencies,
        })

    return {
        "schema_version": "ontos-migration-report-v1",
        "provenance": {
            "generated_at": datetime.now().isoformat(),
            "ontos_version": ontos.__version__,
            "project_root": str(project_root),
        },
        "summary": report.summary,
        "classifications": classifications,
        "warnings": report.warnings,
    }


def migration_report_command(options: MigrationReportOptions) -> Tuple[int, str]:
    """
    Generate migration analysis report.

    Returns:
        Tuple of (exit_code, message)
    """
    try:
        root = find_project_root()
    except Exception as e:
        return 1, f"Error: {e}"

    # Check output file
    if options.output_path:
        if options.output_path.exists() and not options.force:
            return 1, f"Error: Output file exists: {options.output_path}. Use --force to overwrite."

    # Create snapshot and classify
    snapshot = create_snapshot(root)
    report = classify_documents(snapshot)

    # Generate report
    project_name = root.name
    if options.format == "json":
        data = _generate_json_report(report, root)
        output = json.dumps(data, indent=2)
    else:
        output = _generate_markdown_report(report, project_name)

    # Output
    if options.output_path:
        options.output_path.parent.mkdir(parents=True, exist_ok=True)
        options.output_path.write_text(output, encoding='utf-8')
        return 0, f"Generated migration report: {options.output_path}"
    else:
        return 0, output
```

**Commit:**
```
feat(migration): add migration-report command

- Add MigrationReportOptions dataclass
- Add migration_report_command() function
- Support markdown and JSON output formats
- Include override warnings section
```

---

### Task 6: Create Migrate Convenience Command

**Purpose:** Run export data + migration-report together.

**Files:**
- `ontos/commands/migrate_cmd.py` — CREATE (note: different name to avoid conflict with existing migrate.py)

**Code:**

```python
"""
Migrate convenience command — runs export data + migration-report.

Note: Named migrate_cmd.py to avoid conflict with existing migrate.py (schema migration).
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple

from ontos.commands.export_data import export_data_command, ExportDataOptions
from ontos.commands.migration_report import migration_report_command, MigrationReportOptions
from ontos.io.files import find_project_root


@dataclass
class MigrateOptions:
    """Options for migrate convenience command."""
    out_dir: Path = Path("./migration/")
    force: bool = False
    quiet: bool = False
    json_output: bool = False


def migrate_convenience_command(options: MigrateOptions) -> Tuple[int, str]:
    """
    Run export data + migration-report together.

    Creates:
    - {out_dir}/snapshot.json
    - {out_dir}/analysis.md

    Returns:
        Tuple of (exit_code, message)
    """
    try:
        root = find_project_root()
    except Exception as e:
        return 1, f"Error: {e}"

    # Create output directory
    out_dir = options.out_dir
    if not out_dir.is_absolute():
        out_dir = root / out_dir

    try:
        out_dir.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        return 1, f"Error creating output directory: {e}"

    # Run export data
    export_options = ExportDataOptions(
        output_path=out_dir / "snapshot.json",
        force=options.force,
        quiet=True,
    )
    export_code, export_msg = export_data_command(export_options)
    if export_code != 0:
        return export_code, f"Export failed: {export_msg}"

    # Run migration report
    report_options = MigrationReportOptions(
        output_path=out_dir / "analysis.md",
        format="md",
        force=options.force,
        quiet=True,
    )
    report_code, report_msg = migration_report_command(report_options)
    if report_code != 0:
        return report_code, f"Report failed: {report_msg}"

    return 0, f"Migration artifacts created in {out_dir}/\n  - snapshot.json\n  - analysis.md"
```

**Commit:**
```
feat(migration): add migrate convenience command

- Add MigrateOptions dataclass
- Add migrate_convenience_command() function
- Orchestrates export data + migration-report
- Creates snapshot.json and analysis.md in --out-dir
```

---

### Task 7: Update CLI with Subcommand Pattern

**Purpose:** Register all new commands with export subcommands.

**Files:**
- `ontos/cli.py` — MODIFY

**Current Code to Replace (lines 181-188):**
```python
def _register_export(subparsers, parent):
    """Register export command (deprecated alias for agents)."""
    p = subparsers.add_parser("export", help="(Deprecated) Use 'ontos agents' instead", parents=[parent])
    p.add_argument("--force", "-f", action="store_true",
                   help="Overwrite existing file")
    p.add_argument("--output", "-o", type=Path,
                   help="Output path")
    p.set_defaults(func=_cmd_export)
```

**New Code:**
```python
def _register_export(subparsers, parent):
    """Register export command with subcommands."""
    export_parser = subparsers.add_parser(
        "export",
        help="Export documents (use 'export data' or 'export claude')",
        parents=[parent]
    )
    export_subparsers = export_parser.add_subparsers(
        dest="export_command",
        title="export commands",
        metavar="<command>"
    )

    # export data
    data_parser = export_subparsers.add_parser(
        "data",
        help="Export documents as structured JSON",
        parents=[parent]
    )
    data_parser.add_argument("-o", "--output", type=Path,
                             help="Output file path")
    data_parser.add_argument("--type",
                             help="Filter by document type (comma-separated)")
    data_parser.add_argument("--status",
                             help="Filter by status (comma-separated)")
    data_parser.add_argument("--concept",
                             help="Filter by concept (comma-separated)")
    data_parser.add_argument("--no-content", action="store_true",
                             help="Exclude document content")
    data_parser.add_argument("--deterministic", action="store_true",
                             help="Stable output for testing")
    data_parser.add_argument("--force", "-f", action="store_true",
                             help="Overwrite existing file")
    data_parser.set_defaults(func=_cmd_export_data)

    # export claude
    claude_parser = export_subparsers.add_parser(
        "claude",
        help="Generate CLAUDE.md file",
        parents=[parent]
    )
    claude_parser.add_argument("-o", "--output", type=Path,
                               help="Output path (default: CLAUDE.md)")
    claude_parser.add_argument("--force", "-f", action="store_true",
                               help="Overwrite existing file")
    claude_parser.set_defaults(func=_cmd_export_claude)

    # Deprecated: bare 'export' defaults to 'export claude' with warning
    export_parser.set_defaults(func=_cmd_export_deprecated)


def _register_migration_report(subparsers, parent):
    """Register migration-report command."""
    p = subparsers.add_parser(
        "migration-report",
        help="Analyze documents for migration safety",
        parents=[parent]
    )
    p.add_argument("-o", "--output", type=Path,
                   help="Output file path")
    p.add_argument("--format", choices=["md", "json"], default="md",
                   help="Output format (default: md)")
    p.add_argument("--force", "-f", action="store_true",
                   help="Overwrite existing file")
    p.set_defaults(func=_cmd_migration_report)


def _register_migrate_convenience(subparsers, parent):
    """Register migrate convenience command."""
    p = subparsers.add_parser(
        "migrate",
        help="Generate migration artifacts (snapshot + report)",
        parents=[parent]
    )
    p.add_argument("--out-dir", type=Path, default=Path("./migration/"),
                   help="Output directory (default: ./migration/)")
    p.add_argument("--force", "-f", action="store_true",
                   help="Overwrite existing files")
    p.set_defaults(func=_cmd_migrate_convenience)
```

**Add to command registrations (around line 95):**
```python
    _register_migration_report(subparsers, global_parser)
    _register_migrate_convenience(subparsers, global_parser)
```

**Add command handlers (after existing handlers, around line 640):**
```python
def _cmd_export_data(args) -> int:
    """Handle export data command."""
    from ontos.commands.export_data import export_data_command, ExportDataOptions

    options = ExportDataOptions(
        output_path=args.output,
        types=args.type,
        status=args.status,
        concepts=args.concept,
        no_content=args.no_content,
        deterministic=args.deterministic,
        force=args.force,
        quiet=args.quiet,
        json_output=args.json,
    )

    exit_code, message = export_data_command(options)

    if exit_code == 0 and not args.output:
        # Output is JSON to stdout
        print(message)
    elif args.json:
        emit_json({
            "status": "success" if exit_code == 0 else "error",
            "message": message if args.output else "Exported to stdout",
            "exit_code": exit_code
        })
    elif not args.quiet:
        print(message)

    return exit_code


def _cmd_export_claude(args) -> int:
    """Handle export claude command."""
    from ontos.commands.export_claude import export_claude_command, ExportClaudeOptions

    options = ExportClaudeOptions(
        output_path=args.output,
        force=args.force,
        quiet=args.quiet,
        json_output=args.json,
    )

    exit_code, message = export_claude_command(options)

    if args.json:
        emit_json({
            "status": "success" if exit_code == 0 else "error",
            "message": message,
            "exit_code": exit_code
        })
    elif not args.quiet:
        print(message)

    return exit_code


def _cmd_export_deprecated(args) -> int:
    """Handle deprecated bare export command."""
    import sys
    print("Warning: 'ontos export' is deprecated. Use 'ontos export claude' or 'ontos export data'.", file=sys.stderr)
    print("This alias will be removed in v3.4.", file=sys.stderr)

    # Delegate to export claude
    return _cmd_export_claude(args)


def _cmd_migration_report(args) -> int:
    """Handle migration-report command."""
    from ontos.commands.migration_report import migration_report_command, MigrationReportOptions

    options = MigrationReportOptions(
        output_path=args.output,
        format=args.format,
        force=args.force,
        quiet=args.quiet,
        json_output=args.json,
    )

    exit_code, message = migration_report_command(options)

    if exit_code == 0 and not args.output:
        # Output is report to stdout
        print(message)
    elif args.json:
        emit_json({
            "status": "success" if exit_code == 0 else "error",
            "message": message if args.output else "Report output to stdout",
            "exit_code": exit_code
        })
    elif not args.quiet:
        print(message)

    return exit_code


def _cmd_migrate_convenience(args) -> int:
    """Handle migrate convenience command."""
    from ontos.commands.migrate_cmd import migrate_convenience_command, MigrateOptions

    options = MigrateOptions(
        out_dir=args.out_dir,
        force=args.force,
        quiet=args.quiet,
        json_output=args.json,
    )

    exit_code, message = migrate_convenience_command(options)

    if args.json:
        emit_json({
            "status": "success" if exit_code == 0 else "error",
            "message": message,
            "exit_code": exit_code
        })
    elif not args.quiet:
        print(message)

    return exit_code
```

**Note:** The existing `_register_migrate` (schema migration) at lines 251-268 uses the same command name. You need to rename it to `_register_schema_migrate` and change its registration to `"schema-migrate"` or similar to avoid conflict. Alternatively, check with CA on naming convention.

**Commit:**
```
feat(cli): add export subcommands and migration commands

- Replace export registration with subcommand pattern
- Add export data, export claude subcommands
- Add deprecation warning for bare 'ontos export'
- Add migration-report command
- Add migrate convenience command
```

---

### Task 8: Add Command Tests

**Purpose:** Verify all commands work correctly.

**Files:**
- `tests/commands/test_export_data_parity.py` — CREATE
- `tests/commands/test_migration_report_parity.py` — CREATE

**Test for export data (`tests/commands/test_export_data_parity.py`):**

```python
"""Tests for export data command."""

import json
import subprocess
import sys
import pytest
from pathlib import Path


class TestExportDataCommand:
    """Tests for ontos export data command."""

    def test_export_data_help(self):
        """Verify --help works."""
        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export", "data", "--help"],
            capture_output=True,
            text=True
        )
        assert result.returncode == 0
        assert "--output" in result.stdout
        assert "--type" in result.stdout
        assert "--deterministic" in result.stdout

    def test_export_data_to_file(self, tmp_path):
        """Export documents to JSON file."""
        # Setup project
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "test.md").write_text("---\nid: test\ntype: atom\nstatus: active\n---\n# Test\n")

        output = tmp_path / "export.json"

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export", "data", "-o", str(output)],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        assert output.exists()

        data = json.loads(output.read_text())
        assert data["schema_version"] == "ontos-export-v1"
        assert len(data["documents"]) == 1
        assert data["documents"][0]["id"] == "test"

    def test_export_data_deterministic(self, tmp_path):
        """Deterministic mode produces stable output."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "a.md").write_text("---\nid: aaa\ntype: atom\nstatus: active\n---\n")
        (docs / "b.md").write_text("---\nid: bbb\ntype: atom\nstatus: active\n---\n")

        out1 = tmp_path / "out1.json"
        out2 = tmp_path / "out2.json"

        # Run twice
        for out in [out1, out2]:
            subprocess.run(
                [sys.executable, "-m", "ontos", "export", "data", "--deterministic", "-o", str(out)],
                cwd=str(tmp_path)
            )

        # Should be identical
        assert out1.read_text() == out2.read_text()

    def test_export_data_type_filter(self, tmp_path):
        """Type filter restricts output."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "k.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")
        (docs / "a.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        output = tmp_path / "export.json"

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export", "data", "--type", "kernel", "-o", str(output)],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        data = json.loads(output.read_text())
        assert len(data["documents"]) == 1
        assert data["documents"][0]["type"] == "kernel"


class TestExportClaudeCommand:
    """Tests for ontos export claude command."""

    def test_export_claude_help(self):
        """Verify --help works."""
        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export", "claude", "--help"],
            capture_output=True,
            text=True
        )
        assert result.returncode == 0
        assert "--output" in result.stdout
        assert "--force" in result.stdout

    def test_export_claude_creates_file(self, tmp_path):
        """Export claude creates CLAUDE.md."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        (tmp_path / ".git").mkdir()  # Fake git repo

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export", "claude"],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        assert (tmp_path / "CLAUDE.md").exists()


class TestExportDeprecation:
    """Tests for deprecated bare export command."""

    def test_bare_export_warns(self, tmp_path):
        """Bare 'ontos export' prints deprecation warning."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        (tmp_path / ".git").mkdir()

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "export"],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        # Should warn in stderr
        assert "deprecated" in result.stderr.lower()
        assert "v3.4" in result.stderr
```

**Test for migration-report (`tests/commands/test_migration_report_parity.py`):**

```python
"""Tests for migration-report command."""

import json
import subprocess
import sys
import pytest
from pathlib import Path


class TestMigrationReportCommand:
    """Tests for ontos migration-report command."""

    def test_migration_report_help(self):
        """Verify --help works."""
        result = subprocess.run(
            [sys.executable, "-m", "ontos", "migration-report", "--help"],
            capture_output=True,
            text=True
        )
        assert result.returncode == 0
        assert "--output" in result.stdout
        assert "--format" in result.stdout

    def test_migration_report_markdown(self, tmp_path):
        """Generate markdown report."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "k.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")
        (docs / "a.md").write_text("---\nid: a1\ntype: atom\nstatus: active\n---\n")

        output = tmp_path / "report.md"

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "migration-report", "-o", str(output)],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        assert output.exists()
        content = output.read_text()
        assert "# Migration Report" in content
        assert "Safe to migrate" in content or "Safe to Migrate" in content

    def test_migration_report_json(self, tmp_path):
        """Generate JSON report."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "k.md").write_text("---\nid: k1\ntype: kernel\nstatus: active\n---\n")

        output = tmp_path / "report.json"

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "migration-report", "--format", "json", "-o", str(output)],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        data = json.loads(output.read_text())
        assert data["schema_version"] == "ontos-migration-report-v1"
        assert "summary" in data
        assert "classifications" in data


class TestMigrateConvenienceCommand:
    """Tests for ontos migrate convenience command."""

    def test_migrate_help(self):
        """Verify --help works."""
        result = subprocess.run(
            [sys.executable, "-m", "ontos", "migrate", "--help"],
            capture_output=True,
            text=True
        )
        assert result.returncode == 0
        assert "--out-dir" in result.stdout

    def test_migrate_creates_artifacts(self, tmp_path):
        """Migrate creates both files."""
        config = tmp_path / ".ontos.toml"
        config.write_text("[ontos]\nversion = '3.2'\n")
        docs = tmp_path / "docs"
        docs.mkdir()
        (docs / "test.md").write_text("---\nid: test\ntype: atom\nstatus: active\n---\n")

        out_dir = tmp_path / "migration"

        result = subprocess.run(
            [sys.executable, "-m", "ontos", "migrate", "--out-dir", str(out_dir)],
            capture_output=True,
            text=True,
            cwd=str(tmp_path)
        )

        assert result.returncode == 0
        assert (out_dir / "snapshot.json").exists()
        assert (out_dir / "analysis.md").exists()
```

**Commit:**
```
test: add tests for export and migration commands

- Add test_export_data_parity.py
- Add test_migration_report_parity.py
- Test help, file output, filters, deprecation warning
```

---

## Regression Testing Protocol

After EACH task:
```bash
pytest tests/ -v
```

If tests fail:
1. Do NOT proceed to next task
2. Fix the regression
3. Verify all tests pass
4. Then continue

---

## Final Verification

After all tasks complete:

```bash
# Full test suite
pytest tests/ -v

# Manual smoke tests
cd /path/to/test/project  # Any Ontos project

ontos export data -o /tmp/test.json
cat /tmp/test.json | python3 -m json.tool | head -50

ontos export claude --force
cat CLAUDE.md | head -20

ontos export 2>&1 | grep -i deprecated
# Should see deprecation warning

ontos migration-report
# Should output markdown to stdout

ontos migrate --out-dir /tmp/migration/ --force
ls -la /tmp/migration/
# Should see snapshot.json and analysis.md
```

---

## PR Preparation

**Branch:** `feature/v3.2-rearch-support`

**PR Title:** `feat: v3.2 Re-Architecture Support`

**PR Description:**
```markdown
## Summary

Adds Re-Architecture Support to Ontos — bulk data export, migration analysis, and convenience workflows.

## Changes

- [x] Added `ontos export data` command (JSON export with filters)
- [x] Added `ontos export claude` subcommand (CLAUDE.md generation)
- [x] Added deprecation warning for bare `ontos export`
- [x] Added `ontos migration-report` command (safe/review/rewrite classification)
- [x] Added `ontos migrate` convenience command
- [x] Added shared snapshot primitive (`core/snapshot.py`)
- [x] Added migration classification logic (`core/migration.py`)

## Testing

- [x] All existing tests pass
- [x] New tests added for all commands
- [x] Manual verification completed

## Documentation

- [ ] CLI reference updated (Task 9 - not included in this prompt)
- [ ] Agent instructions updated (Task 9)
```

**Expected Commits:**
1. `feat(core): add snapshot primitive`
2. `feat(core): add migration classification logic`
3. `feat(export): add export data command`
4. `refactor(export): extract export claude to dedicated module`
5. `feat(migration): add migration-report command`
6. `feat(migration): add migrate convenience command`
7. `feat(cli): add export subcommands and migration commands`
8. `test: add tests for export and migration commands`

---

## Critical Instructions

1. **Follow the spec exactly.** Do not add features not in the spec.
2. **Follow existing patterns.** Match the code style in `ontos/commands/stub.py`.
3. **Test after every task.** Do not accumulate untested changes.
4. **Commit atomically.** One logical change per commit.
5. **Flag blockers immediately.** If instructions are unclear, ask before guessing.

---

## If You Get Stuck

If any instruction is ambiguous:
1. State what's unclear
2. State your assumption
3. Ask for clarification before proceeding

Do NOT guess on architectural decisions.

---

## Known Issue: Command Name Conflict

**Issue:** The existing `ontos migrate` command (lines 251-268 in cli.py) handles schema migration. The new `ontos migrate` convenience command conflicts with this.

**Resolution Options:**
1. Rename existing to `ontos schema-migrate`
2. Rename new convenience command to `ontos migration`
3. Keep both under `migrate` with subcommands

**Recommendation:** Ask CA for decision before implementing Task 7.
