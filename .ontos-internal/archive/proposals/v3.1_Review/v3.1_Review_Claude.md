I'll fetch both the PyPI page and the GitHub repository to give you a thorough analysis.Let me dig into the actual source code and structure.Let me clone the repository and analyze it directly.Let me install the package directly and examine the source code that way.Now I have enough to give you a thorough review. Let me break this down.

---

## Overall Assessment

This is a well-architected, thoughtfully designed package. The codebase shows deliberate craftsmanship—clean separation of concerns, minimal dependencies, and a clear vision. It's evident you've iterated through multiple internal versions before going public.

---

## Strengths

**1. Architecture quality is genuinely high**

The Phase 2 decomposition is apparent throughout. Core modules (`graph.py`, `schema.py`, `types.py`) are pure with no circular dependencies. The separation between core logic, commands layer, and I/O is clean:

```
core/  → Pure functions, no I/O
commands/ → Orchestration, CLI handling  
io/ → File system, git, config loading
```

The dependency injection pattern in `config.py` (accepting `git_username_provider` callbacks) shows you're thinking about testability.

**2. Minimal footprint**

66 Python files, single dependency (PyYAML). This is refreshing. The tool does one thing and doesn't try to be an ecosystem.

**3. Schema versioning done right**

The schema detection with fallback inference is smart:

```python
# Priority 1: Explicit schema declaration
if 'ontos_schema' in frontmatter:
    return frontmatter['ontos_schema']
# Priority 2: Field inference for legacy documents
if 'implements' in frontmatter:
    return "3.0"
```

Forward compatibility planning is visible. This will age well.

**4. CLI design is solid**

Global flags (`--json`, `--quiet`) work consistently. Exit codes follow conventions. The `doctor` command with 8 health checks is genuinely useful. The JSON output option makes it automation-friendly.

**5. Documentation and philosophy**

The README is excellent. "Context dies in three ways" - that's a hook. The philosophy section ("Intent over automation") sets expectations correctly. The FAQ explaining "Why v3?" shows maturity.

**6. The hierarchy concept is sound**

The kernel → strategy → product → atom layering makes sense. The question "If this doc changes, what else breaks?" is the right mental model.

---

## Criticisms and Risks

**1. Self-referential document problem**

When I ran `ontos map`, it picked up `AGENTS.md` and `Ontos_Context_Map.md` as documents:

```
| /tmp/test-ontos/AGENTS.md | `AGENTS` | atom | draft |
| /tmp/test-ontos/Ontos_Context_Map.md | `ontos_context_map` | atom | draft |
```

This is confusing. Generated files shouldn't appear in the graph they describe. You need skip patterns for these, or smarter detection.

**2. Namespace collision risk**

Databricks Labs has a project called `databrickslabs/ontos` on GitHub. Completely different tool (data product management for Unity Catalog). Same PyPI-adjacent search space. This creates:
- Discovery confusion
- SEO competition  
- Potential future trademark issues

I'm not saying rename, but be aware this exists.

**3. Legacy script baggage**

The `_scripts/` directory contains legacy implementations that are still wrapped via subprocess in some paths. The comment in `cli.py`:

```python
def _cmd_wrapper(args) -> int:
    """Handle wrapper commands that delegate to legacy scripts."""
```

This is tech debt. If v3.1 is supposed to be native Python throughout, those should be gone. The dual paths add complexity.

**4. Version number confusion**

- Package version: 3.1.0
- Schema version: 2.2 (current)
- Config version: "3.0"

Three different versioning tracks. The schema `CURRENT_SCHEMA_VERSION = "2.2"` while the tool is 3.1.0 will confuse users. Why isn't schema 3.0 current with tool 3.x?

**5. Type handling inconsistencies**

The scaffold output shows `type: unknown` for documents it can't classify:

```
docs/test.md
    type: unknown
```

But `unknown` isn't in your `DocumentType` enum. The type coercion works but it's a bit loose:

```python
doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
```

This pattern appears everywhere. Consider a helper function or making it more explicit.

**6. Discovery and visibility**

1 star on GitHub. The package exists in a void right now. For a tool that's supposed to help teams and AI agents work together, you need:
- More examples/templates
- Integration guides (Cursor, Claude Code, etc.)
- Community presence

**7. Empty initialization**

`ontos init` creates empty directory structures (`docs/strategy/`, `docs/reference/`, etc.) but no template files. A new user stares at an empty `docs/` folder. Consider shipping a minimal template (`_template.md`) that shows frontmatter structure.

**8. The "describes" staleness feature is hidden**

The staleness detection for `describes` fields is a powerful concept that's buried in the code. The README doesn't explain it well. This could be a differentiator but it's undersold.

---

## Suggestions for Improvement

**Immediate (v3.1.x)**

1. Add skip patterns for `AGENTS.md` and `*_Context_Map.md` in default config
2. Ship a `_template.md` file during init
3. Consolidate the version story in documentation
4. Clean up legacy script wrappers

**Medium-term (v3.2)**

1. Add type validation in scaffold (reject or warn on `unknown`)
2. Better error messages when schema inference fails
3. Integration examples with Claude Code, Cursor, Windsurf
4. Consider MCP server implementation (you mention this in roadmap)

**Long-term**

1. Address the namespace collision—maybe through better SEO, or eventually a more unique name for broader adoption
2. Build out the template system you mention in v4.0 roadmap
3. Community building

---

## Bottom Line

This is solid engineering work with a clear vision. The core concept is sound, the implementation is clean, and it scratches a real itch. The risks are mostly around discoverability and polish, not fundamental design flaws.

The main things holding it back from wider adoption are: (1) the namespace collision making it hard to find, (2) lack of templates making onboarding feel empty, and (3) the self-referential document bug which breaks the promise of "deterministic" output.

You've built something genuinely useful. Now it needs the rough edges sanded down and some visibility.